#!/usr/bin/env python3
"""
NETEZZA â†’ PostgreSQL ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ (ë²”ìš©)
ëª¨ë“  í…Œì´ë¸”ì„ ì„¤ì • íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜
"""

import os
import sys
import pandas as pd
try:
    import nzpy  # NETEZZA ì—°ê²°ìš© (Pure Python, ODBC ë¶ˆí•„ìš”)
    USE_NZPY = True
except ImportError:
    import pyodbc  # ODBC ëŒ€ì²´
    USE_NZPY = False
from sqlalchemy import create_engine, text
import logging
from datetime import datetime
from dotenv import load_dotenv

# ì„¤ì • íŒŒì¼ ì„í¬íŠ¸
try:
    from migrate_tables_config import get_enabled_tables, get_table_config
except ImportError:
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from migrate_tables_config import get_enabled_tables, get_table_config

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def connect_netezza():
    """NETEZZA ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (nzpy ë˜ëŠ” pyodbc)"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ NETEZZA ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    netezza_host = os.getenv('NETEZZA_HOST', 'your_netezza_host')
    netezza_port = int(os.getenv('NETEZZA_PORT', '5480'))
    netezza_db = os.getenv('NETEZZA_DATABASE', 'your_database')
    netezza_user = os.getenv('NETEZZA_USER', 'your_username')
    netezza_pwd = os.getenv('NETEZZA_PASSWORD', 'your_password')
    
    try:
        logger.info(f"ğŸ”Œ NETEZZA ì—°ê²° ì‹œë„: {netezza_host}:{netezza_port}/{netezza_db}")
        
        if USE_NZPY:
            # nzpy ì‚¬ìš© (Pure Python, ODBC ë¶ˆí•„ìš”)
            logger.info("   ì—°ê²° ë°©ì‹: nzpy (Pure Python)")
            conn = nzpy.connect(
                host=netezza_host,
                port=netezza_port,
                database=netezza_db,
                user=netezza_user,
                password=netezza_pwd,
                securityLevel=0,  # ë³´ì•ˆ ìˆ˜ì¤€ (0=ë¹„ì•”í˜¸í™”)
                logLevel=0
            )
            logger.info("âœ… NETEZZA ì—°ê²° ì„±ê³µ (nzpy)")
        else:
            # pyodbc ì‚¬ìš© (ODBC ë“œë¼ì´ë²„ í•„ìš”)
            logger.info("   ì—°ê²° ë°©ì‹: pyodbc (ODBC)")
            netezza_driver = os.getenv('NETEZZA_DRIVER', 'NetezzaSQL')
            conn_string = (
                f"DRIVER={{{netezza_driver}}};"
                f"SERVER={netezza_host};"
                f"PORT={netezza_port};"
                f"DATABASE={netezza_db};"
                f"UID={netezza_user};"
                f"PWD={netezza_pwd};"
            )
            conn = pyodbc.connect(conn_string)
            logger.info("âœ… NETEZZA ì—°ê²° ì„±ê³µ (pyodbc)")
        
        return conn
        
    except Exception as e:
        logger.error(f"âŒ NETEZZA ì—°ê²° ì‹¤íŒ¨: {e}")
        logger.error(f"   í˜¸ìŠ¤íŠ¸: {netezza_host}:{netezza_port}")
        logger.error(f"   ë°ì´í„°ë² ì´ìŠ¤: {netezza_db}")
        logger.error(f"   ì‚¬ìš©ì: {netezza_user}")
        raise


def connect_postgres():
    """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ DB URI ê°€ì ¸ì˜¤ê¸°
    db_uri = os.getenv('DB_URI') or os.getenv('POSTGRES_URI')
    
    # Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œëŠ” í˜¸ìŠ¤íŠ¸ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
    if not db_uri:
        db_uri = "postgresql://TRN_AI:TRN_AI@trnAi_postgres:5432/TRNAI_DB"
    
    try:
        engine = create_engine(db_uri)
        logger.info("âœ… PostgreSQL ì—°ê²° ì„±ê³µ")
        return engine
    except Exception as e:
        logger.error(f"âŒ PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
        raise


def extract_table_from_netezza(netezza_conn, table_name, incremental=True):
    """NETEZZAì—ì„œ í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ (ë²”ìš©)
    
    Args:
        netezza_conn: NETEZZA ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        table_name: í…Œì´ë¸”ëª… (ì˜ˆ: TAIGOODS, TAIPGMTAPE)
        incremental: Trueë©´ ì–´ì œ ì´í›„ ìˆ˜ì •ëœ ë°ì´í„°ë§Œ, Falseë©´ ì „ì²´ ë°ì´í„°
    """
    
    # í…Œì´ë¸” ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    config = get_table_config(table_name)
    if not config:
        logger.error(f"âŒ í…Œì´ë¸” ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {table_name}")
        return None
    
    # ì¿¼ë¦¬ ìƒì„± (ì„¤ì • íŒŒì¼ì˜ ëŒë‹¤ í•¨ìˆ˜ ì‹¤í–‰)
    query = config["query"](incremental)
    
    # ë¡œê·¸ ì¶œë ¥
    mode = f"ì¦ë¶„ ì—…ë°ì´íŠ¸" if incremental else "ì „ì²´ ë°ì´í„°"
    logger.info(f"ğŸ“¥ NETEZZAì—ì„œ {table_name} ì¶”ì¶œ ì¤‘ ({mode})...")
    logger.debug(f"   ì¿¼ë¦¬: {query[:200]}...")
    
    try:
        df = pd.read_sql(query, netezza_conn)
        logger.info(f"   âœ… ì¶”ì¶œ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
        return df
    except Exception as e:
        logger.error(f"   âŒ {table_name} ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


def upsert_to_postgres(df, table_name, postgres_engine, key_column='product_code'):
    """PostgreSQLì— ë°ì´í„° UPSERT (ì¡´ì¬í•˜ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì‚½ì…)
    
    Args:
        df: ì ì¬í•  ë°ì´í„°í”„ë ˆì„
        table_name: í…Œì´ë¸”ëª… (taigoods ë˜ëŠ” taipgmtape)
        postgres_engine: PostgreSQL ì—”ì§„
        key_column: Primary Key ì»¬ëŸ¼ëª…
    """
    
    logger.info(f"ğŸ“¤ PostgreSQL {table_name} í…Œì´ë¸”ì— UPSERT ì¤‘...")
    
    if len(df) == 0:
        logger.warning("   âš ï¸  ì ì¬í•  ë°ì´í„° ì—†ìŒ")
        return True
    
    try:
        from sqlalchemy import text
        
        # ì„ì‹œ í…Œì´ë¸”ì— ë°ì´í„° ì ì¬ (PostgreSQLì€ ì†Œë¬¸ìë¡œ í†µì¼)
        temp_table = f"{table_name.lower()}_temp"
        df.to_sql(
            temp_table,
            postgres_engine,
            if_exists='replace',
            index=False,
            method='multi',
            chunksize=1000
        )
        
        # UPSERT ì¿¼ë¦¬ ì‹¤í–‰ (ON CONFLICT DO UPDATE)
        if table_name.lower() == 'taigoods':
            upsert_query = f"""
            INSERT INTO taigoods (product_code, product_name, category_main, category_middle, 
                                  category_sub, price, brand, product_type, created_at, updated_at)
            SELECT product_code, product_name, category_main, category_middle, 
                   category_sub, price::NUMERIC, brand, product_type, 
                   created_at::TIMESTAMP, CURRENT_TIMESTAMP
            FROM {temp_table}
            ON CONFLICT (product_code) DO UPDATE SET
                product_name = EXCLUDED.product_name,
                category_main = EXCLUDED.category_main,
                category_middle = EXCLUDED.category_middle,
                category_sub = EXCLUDED.category_sub,
                price = EXCLUDED.price,
                brand = EXCLUDED.brand,
                product_type = EXCLUDED.product_type,
                updated_at = CURRENT_TIMESTAMP
            """
        elif table_name.lower() == 'taipgmtape':
            upsert_query = f"""
            INSERT INTO taipgmtape (tape_code, tape_name, product_code, production_status, 
                                    created_at, updated_at)
            SELECT tape_code, tape_name, product_code, production_status, 
                   created_at::TIMESTAMP, CURRENT_TIMESTAMP
            FROM {temp_table}
            ON CONFLICT (tape_code) DO UPDATE SET
                tape_name = EXCLUDED.tape_name,
                product_code = EXCLUDED.product_code,
                production_status = EXCLUDED.production_status,
                updated_at = CURRENT_TIMESTAMP
            """
        elif table_name.lower() == 'taibroadcasts':
            # TAIPGMTAPEì— ì¡´ì¬í•˜ëŠ” tape_codeë§Œ ì‚½ì… (Foreign Key ì œì•½ ì¤€ìˆ˜)
            upsert_query = f"""
            INSERT INTO taibroadcasts (tape_code, broadcast_start_timestamp, product_is_new, 
                                       gross_profit, sales_efficiency, created_at)
            SELECT t.tape_code, 
                   t.broadcast_start_timestamp::TIMESTAMP, 
                   CASE WHEN t.product_is_new IS NULL THEN FALSE 
                        ELSE t.product_is_new::BOOLEAN 
                   END, 
                   t.gross_profit::NUMERIC, 
                   t.sales_efficiency::NUMERIC, 
                   t.created_at::TIMESTAMP
            FROM {temp_table} t
            WHERE EXISTS (SELECT 1 FROM taipgmtape WHERE tape_code = t.tape_code)
            """
        elif table_name.lower() == 'taicompetitor_broadcasts':
            # ê²½ìŸì‚¬ ë°©ì†¡ ì •ë³´ UPSERT
            # 1. ê³ ìœ  ì¸ë±ìŠ¤ ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)
            create_index_query = """
            CREATE UNIQUE INDEX IF NOT EXISTS ux_taicomp_brdcst_date_slot_comp 
            ON taicompetitor_broadcasts (broadcast_date, time_slot, competitor_name)
            """
            with postgres_engine.connect() as conn:
                conn.execute(text(create_index_query))
                conn.commit()
            
            # 2. UPSERT ì‹¤í–‰
            upsert_query = f"""
            INSERT INTO taicompetitor_broadcasts (broadcast_date, time_slot, competitor_name, 
                                                   category_main, category_middle, created_at)
            SELECT broadcast_date::DATE, 
                   time_slot, 
                   competitor_name, 
                   category_main, 
                   category_middle,
                   CURRENT_TIMESTAMP
            FROM {temp_table}
            ON CONFLICT (broadcast_date, time_slot, competitor_name)
            DO UPDATE SET
                category_main = EXCLUDED.category_main,
                category_middle = EXCLUDED.category_middle,
                created_at = CURRENT_TIMESTAMP
            """
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸”: {table_name}")
        
        with postgres_engine.connect() as conn:
            conn.execute(text(upsert_query))
            conn.commit()
        
        # ì„ì‹œ í…Œì´ë¸” ì‚­ì œ
        with postgres_engine.connect() as conn:
            conn.execute(text(f"DROP TABLE IF EXISTS {temp_table}"))
            conn.commit()
        
        logger.info(f"   âœ… {len(df)}ê°œ ë ˆì½”ë“œ UPSERT ì™„ë£Œ")
        return True
    except Exception as e:
        logger.error(f"   âŒ UPSERT ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def convert_time_slot(start_time, end_time):
    """ì‹œì‘/ì¢…ë£Œ ì‹œê°„ì„ time_slotìœ¼ë¡œ ë³€í™˜
    
    Args:
        start_time: ì‹œì‘ ì‹œê°„ (ì˜ˆ: "2025-10-15 14:30:00.000")
        end_time: ì¢…ë£Œ ì‹œê°„ (ì˜ˆ: "2025-10-15 15:30:00.000")
    
    Returns:
        time_slot: ì‹œê°„ëŒ€ ë¬¸ìì—´ (ì˜ˆ: "14:00-16:00")
    """
    try:
        # ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜
        if pd.isna(start_time) or pd.isna(end_time):
            return "00:00-01:00"
        
        start_str = str(start_time)
        end_str = str(end_time)
        
        # ì‹œê°„ ì¶”ì¶œ (ì—¬ëŸ¬ í˜•ì‹ ëŒ€ì‘)
        if len(start_str) >= 19:  # "2025-10-15 14:30:00" í˜•ì‹
            start_hour = int(start_str[11:13])
            end_hour = int(end_str[11:13])
            end_minute = int(end_str[14:16])
            
            # ì¢…ë£Œ ì‹œê°„ì´ ì •ê°ì´ ì•„ë‹ˆë©´ ë‹¤ìŒ ì‹œê°„ìœ¼ë¡œ ì˜¬ë¦¼
            if end_minute > 0:
                end_hour += 1
            
            # 24ì‹œë¥¼ ë„˜ì–´ê°€ëŠ” ê²½ìš° ì²˜ë¦¬
            if end_hour > 24:
                end_hour = 24
            
            return f"{start_hour:02d}:00-{end_hour:02d}:00"
        else:
            return "00:00-01:00"
            
    except Exception as e:
        logger.warning(f"ì‹œê°„ ë³€í™˜ ì‹¤íŒ¨: {start_time} ~ {end_time}, ì—ëŸ¬: {e}")
        return "00:00-01:00"


def data_cleansing(df, table_type='products'):
    """ë°ì´í„° ì •ì œ"""
    
    logger.info("ğŸ§¹ ë°ì´í„° ì •ì œ ì¤‘...")
    
    # NETEZZAëŠ” ì»¬ëŸ¼ëª…ì„ ëŒ€ë¬¸ìë¡œ ë°˜í™˜í•˜ë¯€ë¡œ ì†Œë¬¸ìë¡œ ë³€í™˜
    df.columns = df.columns.str.lower()
    
    if table_type == 'products':
        # NULL ì²˜ë¦¬
        df['product_name'] = df['product_name'].fillna('')
        df['brand'] = df['brand'].fillna('ë¯¸ì§€ì •')
        df['price'] = df['price'].fillna(0)
        
        # ë°ì´í„° íƒ€ì… ë³€í™˜
        df['price'] = pd.to_numeric(df['price'], errors='coerce').fillna(0)
        
        # ìƒí’ˆì½”ë“œ ì¤‘ë³µ ì œê±° (ìµœì‹  ë°ì´í„° ìš°ì„ )
        df = df.drop_duplicates(subset=['product_code'], keep='last')
        
        # ë¹ˆ ìƒí’ˆì½”ë“œ ì œê±°
        df = df[df['product_code'].notna()]
        df = df[df['product_code'] != '']
        
        logger.info(f"   ì •ì œ í›„: {len(df)}ê°œ ìƒí’ˆ")
    
    elif table_type == 'competitors':
        # ê²½ìŸì‚¬ ë°©ì†¡ ë°ì´í„° ì •ì œ
        logger.info("   ê²½ìŸì‚¬ ë°©ì†¡ ë°ì´í„° ì •ì œ ì¤‘...")
        
        # ì»¬ëŸ¼ ë¦¬ë„¤ì„
        df = df.rename(columns={
            'bdcast_dt': 'broadcast_date',
            'strt_dttm': 'start_time',
            'end_dttm': 'end_time',
            'cmpny_nm': 'competitor_name',
            'lcls_ctgr': 'category_main',
            'mcls_ctgr': 'category_middle'
        })
        
        # time_slot ê³„ì‚°
        df['time_slot'] = df.apply(
            lambda row: convert_time_slot(row.get('start_time'), row.get('end_time')), 
            axis=1
        )
        
        # NULL ì²˜ë¦¬
        df['competitor_name'] = df['competitor_name'].fillna('ë¯¸ì§€ì •')
        df['category_main'] = df['category_main'].fillna('ê¸°íƒ€')
        df['category_middle'] = df['category_middle'].fillna('ê¸°íƒ€')
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        df = df[['broadcast_date', 'time_slot', 'competitor_name', 'category_main', 'category_middle']]
        
        # ì¤‘ë³µ ì œê±° (ê°™ì€ ë‚ ì§œ/ì‹œê°„ëŒ€/ê²½ìŸì‚¬ëŠ” ìµœì‹  ë°ì´í„°ë§Œ)
        df = df.drop_duplicates(subset=['broadcast_date', 'time_slot', 'competitor_name'], keep='last')
        
        logger.info(f"   ì •ì œ í›„: {len(df)}ê°œ ê²½ìŸì‚¬ ë°©ì†¡")
    
    return df


def migrate_single_table(netezza_conn, postgres_engine, table_name, incremental=True):
    """ë‹¨ì¼ í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜
    
    Args:
        netezza_conn: NETEZZA ì—°ê²°
        postgres_engine: PostgreSQL ì—”ì§„
        table_name: í…Œì´ë¸”ëª…
        incremental: ì¦ë¶„ ì—…ë°ì´íŠ¸ ì—¬ë¶€
    
    Returns:
        dict: ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ì •ë³´
    """
    
    config = get_table_config(table_name)
    if not config:
        return {"success": False, "table": table_name, "message": "í…Œì´ë¸” ì„¤ì • ì—†ìŒ", "count": 0}
    
    try:
        # 1. ë°ì´í„° ì¶”ì¶œ
        df = extract_table_from_netezza(netezza_conn, table_name, incremental)
        
        if df is None or len(df) == 0:
            logger.warning(f"âš ï¸  {table_name}: ì¶”ì¶œëœ ë°ì´í„° ì—†ìŒ")
            return {"success": True, "table": table_name, "message": "ë°ì´í„° ì—†ìŒ", "count": 0}
        
        # 2. ë°ì´í„° ì •ì œ
        if table_name == 'TAIGOODS':
            table_type = 'products'
        elif table_name == 'TAICOMPETITOR_BROADCASTS':
            table_type = 'competitors'
        else:
            table_type = 'tapes'
        
        df = data_cleansing(df, table_type)
        
        # 3. UPSERT
        primary_key = config["primary_key"]
        success = upsert_to_postgres(df, table_name, postgres_engine, key_column=primary_key)
        
        return {
            "success": success,
            "table": table_name,
            "message": "ì™„ë£Œ" if success else "ì‹¤íŒ¨",
            "count": len(df)
    }
        
    except Exception as e:
        logger.error(f"âŒ {table_name} ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        return {"success": False, "table": table_name, "message": str(e), "count": 0}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ëª¨ë“  í™œì„±í™”ëœ í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜"""
    
    # í™˜ê²½ë³€ìˆ˜ë¡œ ì „ì²´ ì¬ì²˜ë¦¬ ì—¬ë¶€ ê²°ì • (ê¸°ë³¸ê°’: ì¦ë¶„ ì—…ë°ì´íŠ¸)
    full_sync = os.getenv('FULL_SYNC', 'false').lower() == 'true'
    incremental = not full_sync
    
    # íŠ¹ì • í…Œì´ë¸”ë§Œ ë§ˆì´ê·¸ë ˆì´ì…˜ (í™˜ê²½ë³€ìˆ˜)
    target_tables = os.getenv('TABLES', '').split(',') if os.getenv('TABLES') else None
    
    print("=" * 70)
    print("NETEZZA â†’ PostgreSQL ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ (ë²”ìš©)")
    print("=" * 70)
    print(f"ëª¨ë“œ: {'ì „ì²´ ì¬ì²˜ë¦¬' if not incremental else 'ì¦ë¶„ ì—…ë°ì´íŠ¸ (ì–´ì œ ì´í›„)'}")
    if target_tables:
        print(f"ëŒ€ìƒ í…Œì´ë¸”: {', '.join(target_tables)}")
    else:
        print(f"ëŒ€ìƒ í…Œì´ë¸”: ëª¨ë“  í™œì„±í™”ëœ í…Œì´ë¸”")
    print("=" * 70)
    
    try:
        # 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        netezza_conn = connect_netezza()
        postgres_engine = connect_postgres()
        
        # 2. ë§ˆì´ê·¸ë ˆì´ì…˜í•  í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        enabled_tables = get_enabled_tables()
        
        if target_tables:
            # íŠ¹ì • í…Œì´ë¸”ë§Œ í•„í„°ë§
            enabled_tables = {k: v for k, v in enabled_tables.items() if k in target_tables}
        
        if not enabled_tables:
            logger.error("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜í•  í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        logger.info(f"\nğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒ: {len(enabled_tables)}ê°œ í…Œì´ë¸”")
        for table_name, config in enabled_tables.items():
            logger.info(f"   - {table_name}: {config['description']}")
        
        # 3. ê° í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜
        print("\n" + "=" * 70)
        results = []
        
        for table_name in enabled_tables.keys():
            logger.info(f"\n{'='*70}")
            logger.info(f"ğŸ”„ {table_name} ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
            logger.info(f"{'='*70}")
            
            result = migrate_single_table(netezza_conn, postgres_engine, table_name, incremental)
            results.append(result)
            
            if result["success"]:
                logger.info(f"âœ… {table_name}: {result['count']}ê°œ ë ˆì½”ë“œ ì²˜ë¦¬ ì™„ë£Œ")
            else:
                logger.error(f"âŒ {table_name}: {result['message']}")
        
        # 4. ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 70)
        print("ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ìš”ì•½")
        print("=" * 70)
        
        success_count = sum(1 for r in results if r["success"])
        total_count = len(results)
        total_records = sum(r["count"] for r in results)
        
        print(f"ì„±ê³µ: {success_count}/{total_count} í…Œì´ë¸”")
        print(f"ì´ ë ˆì½”ë“œ: {total_records:,}ê°œ")
        print()
        
        for result in results:
            status = "âœ…" if result["success"] else "âŒ"
            print(f"{status} {result['table']:<25} {result['count']:>8,}ê°œ  ({result['message']})")
        
        print("=" * 70)
        
        if success_count == total_count:
            print("\nâœ… ëª¨ë“  í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
            print("\në‹¤ìŒ ë‹¨ê³„:")
            print("  1. ë°ì´í„° í™•ì¸: psqlë¡œ PostgreSQL ì ‘ì†")
            print("  2. ì„ë² ë”© ìƒì„±: docker exec -it fastapi_backend python app/setup_product_embeddings.py")
        else:
            print("\nâš ï¸  ì¼ë¶€ í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨ - ë¡œê·¸ í™•ì¸ í•„ìš”")
        
        # ì—°ê²° ì¢…ë£Œ
        netezza_conn.close()
        postgres_engine.dispose()
        
        # ì¢…ë£Œ ì½”ë“œ ë°˜í™˜ (n8nì—ì„œ í™•ì¸ ê°€ëŠ¥)
        return 0 if success_count == total_count else 1
        
    except Exception as e:
        logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    main()
