"""
ë°©ì†¡ í¸ì„± AI ì¶”ì²œ ì›Œí¬í”Œë¡œìš°
LangChain ê¸°ë°˜ 2ë‹¨ê³„ ì›Œí¬í”Œë¡œìš°: AI ë°©í–¥ íƒìƒ‰ + ê³ ì† ë­í‚¹
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
import pandas as pd
from sqlalchemy import create_engine, text
import os

from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from .external_apis import ExternalAPIManager

from .dependencies import get_product_embedder
from . import broadcast_recommender as br
from .schemas import BroadcastResponse, RecommendedCategory, BroadcastRecommendation, ProductInfo, Reasoning, BusinessMetrics

logger = logging.getLogger(__name__)

class BroadcastWorkflow:
    """ë°©ì†¡ í¸ì„± AI ì¶”ì²œ ì›Œí¬í”Œë¡œìš°"""
    
    def __init__(self, model):
        self.model = model  # XGBoost ëª¨ë¸
        self.product_embedder = get_product_embedder()
        
        # LangChain LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.1,
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # DB ì—°ê²°
        self.engine = create_engine(os.getenv("POSTGRES_URI"))
    
    async def process_broadcast_recommendation(
        self, 
        broadcast_time: str, 
        recommendation_count: int = 5,
        trend_ratio: float = 0.3  # íŠ¸ë Œë“œ ë§¤ì¹­ ë¹„ìœ¨ (0.3 = 30%)
    ) -> BroadcastResponse:
        """ë©”ì¸ ì›Œí¬í”Œë¡œìš°: ë°©ì†¡ ì‹œê°„ ê¸°ë°˜ ì¶”ì²œ
        
        Args:
            broadcast_time: ë°©ì†¡ ì‹œê°„
            recommendation_count: ì¶”ì²œ ê°œìˆ˜
            trend_ratio: íŠ¸ë Œë“œ ë§¤ì¹­ ë¹„ìœ¨ (0.0~1.0, ê¸°ë³¸ 0.3)
                - 0.3 = íŠ¸ë Œë“œ 30%, ë§¤ì¶œì˜ˆì¸¡ 70%
                - 0.5 = ê· í˜• (50:50)
                - 0.0 = ë§¤ì¶œì˜ˆì¸¡ë§Œ (100%)
        """
        
        print("=== [DEBUG] process_broadcast_recommendation ì‹œì‘ ===")
        request_time = datetime.now().isoformat()
        logger.info(f"ë°©ì†¡ ì¶”ì²œ ì›Œí¬í”Œë¡œìš° ì‹œì‘: {broadcast_time}")
        print(f"=== [DEBUG] broadcast_time: {broadcast_time}, recommendation_count: {recommendation_count} ===")
        
        try:
            # 1ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ë° í†µí•© í‚¤ì›Œë“œ ìƒì„±
            print("=== [DEBUG] _collect_context_and_keywords í˜¸ì¶œ ===")
            context = await self._collect_context_and_keywords(broadcast_time)
            print(f"=== [DEBUG] í†µí•© í‚¤ì›Œë“œ: {len(context.get('unified_keywords', []))}ê°œ ===")
            
            # 2. í†µí•© ê²€ìƒ‰ ì‹¤í–‰ (1íšŒ)
            print("=== [DEBUG] _execute_unified_search í˜¸ì¶œ ===")
            search_result = await self._execute_unified_search(context, context.get("unified_keywords", []))
            print(f"=== [DEBUG] ê²€ìƒ‰ ì™„ë£Œ - ì§ì ‘ë§¤ì¹­: {len(search_result['direct_products'])}ê°œ, ì¹´í…Œê³ ë¦¬: {len(search_result['category_groups'])}ê°œ ===")
            
            # 3. í›„ë³´êµ° ìƒì„± (ë¹„ìœ¨ ì¡°ì •)
            print("=== [DEBUG] _generate_unified_candidates í˜¸ì¶œ ===")
            max_trend = max(1, int(recommendation_count * trend_ratio))  # ìµœì†Œ 1ê°œ
            max_sales = recommendation_count - max_trend + 3  # ì—¬ìœ ë¶„ ì¶”ê°€
            print(f"=== [DEBUG] ë¹„ìœ¨ ì¡°ì •: íŠ¸ë Œë“œ {max_trend}ê°œ, ë§¤ì¶œ {max_sales}ê°œ (ë¹„ìœ¨: {trend_ratio:.0%}) ===")
            
            candidate_products, category_scores, top_categories = await self._generate_unified_candidates(
                search_result,
                context,
                max_trend_match=max_trend,
                max_sales_prediction=max_sales
            )
            print(f"=== [DEBUG] í›„ë³´êµ° ìƒì„± ì™„ë£Œ: {len(candidate_products)}ê°œ ===")
            
            # 4. ìµœì¢… ë­í‚¹ ê³„ì‚°
            ranked_products = await self._rank_final_candidates(
                candidate_products,
                category_scores=category_scores,
                context=context
            )
            
            # 5. API ì‘ë‹µ ìƒì„±
            response = await self._format_response(ranked_products[:recommendation_count], top_categories[:3], context)
            response.requestTime = request_time
            
            logger.info(f"ë°©ì†¡ ì¶”ì²œ ì™„ë£Œ: {len(ranked_products)}ê°œ ì¶”ì²œ")
            return response
            
        except Exception as e:
            print(f"=== [DEBUG] ì˜ˆì™¸ ë°œìƒ: {type(e).__name__}: {e} ===")
            import traceback
            traceback.print_exc()
            logger.error(f"ë°©ì†¡ ì¶”ì²œ ì›Œí¬í”Œë¡œìš° ì˜¤ë¥˜: {e}")
            # OpenAI API ê´€ë ¨ ì˜¤ë¥˜ëŠ” ìƒìœ„ë¡œ ì „íŒŒ (503 ì—ëŸ¬ ë°˜í™˜ìš©)
            if "AI ì„œë¹„ìŠ¤" in str(e) or "OpenAI" in str(e) or "í• ë‹¹ëŸ‰" in str(e):
                raise e
            # ê¸°íƒ€ ë‚´ë¶€ ì˜¤ë¥˜ëŠ” 500 ì—ëŸ¬ë¡œ ì²˜ë¦¬
            raise Exception(f"ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜: {e}")
    
    async def _collect_context_and_keywords(self, broadcast_time: str) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ë° í†µí•© í‚¤ì›Œë“œ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        
        # ë°©ì†¡ ì‹œê°„ íŒŒì‹±
        broadcast_dt = datetime.fromisoformat(broadcast_time.replace('Z', '+00:00'))
        
        # DBì—ì„œ ê³µíœ´ì¼ ì •ë³´ ì¡°íšŒ
        holiday_name = await self._get_holiday_from_db(broadcast_dt.date())
        
        context = {
            "broadcast_time": broadcast_time,
            "broadcast_dt": broadcast_dt,
            "hour": broadcast_dt.hour,
            "weekday": broadcast_dt.weekday(),
            "season": self._get_season(broadcast_dt.month),
            "holiday_name": holiday_name  # ê³µíœ´ì¼ ì •ë³´ ì¶”ê°€
        }
        
        # ë‚ ì”¨ ì •ë³´ ìˆ˜ì§‘
        weather_info = br.get_weather_by_date(broadcast_dt.date())
        context["weather"] = weather_info

        # ì‹œê°„ëŒ€ ì •ë³´
        time_slot = self._get_time_slot(broadcast_dt)
        day_type = "ì£¼ë§" if broadcast_dt.weekday() >= 5 else "í‰ì¼"
        context["time_slot"] = time_slot
        context["day_type"] = day_type

        # AI ê¸°ë°˜ íŠ¸ë Œë“œ ìƒì„± (LLM API)
        api_manager = ExternalAPIManager()
        if api_manager.llm_trend_api:
            try:
                # ë°©ì†¡ ì‹œê°„ê³¼ ë‚ ì”¨ ì •ë³´ë¥¼ ì „ë‹¬í•˜ì—¬ ë§¥ë½ ê¸°ë°˜ íŠ¸ë Œë“œ ìƒì„±
                llm_trends = await api_manager.llm_trend_api.get_trending_searches(
                    hour=broadcast_dt.hour,
                    weather_info=weather_info
                )
                # AIê°€ ìƒì„±í•œ íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì¶”ê°€
                context["ai_trends"] = [t["keyword"] for t in llm_trends]
                logger.info(f"AI íŠ¸ë Œë“œ ìƒì„± ì™„ë£Œ ({broadcast_dt.hour}ì‹œ, {weather_info.get('weather', 'N/A')}): {len(llm_trends)}ê°œ í‚¤ì›Œë“œ")
                logger.info(f"AI íŠ¸ë Œë“œ: {context['ai_trends'][:5]}...")  # ìƒìœ„ 5ê°œë§Œ ë¡œê·¸
            except Exception as e:
                logger.error(f"AI íŠ¸ë Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
                context["ai_trends"] = []
        else:
            logger.warning("OpenAI API í‚¤ ì—†ìŒ - AI íŠ¸ë Œë“œ ìƒì„± ê±´ë„ˆëœ€")
            context["ai_trends"] = []

        # ì»¨í…ìŠ¤íŠ¸ ë¡œê·¸ ì¶œë ¥
        logger.info(f"ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ - ê³„ì ˆ: {context['season']}, ì‹œê°„ëŒ€: {time_slot}, ìš”ì¼: {day_type}")
        if holiday_name:
            logger.info(f"ğŸ‰ ê³µíœ´ì¼: {holiday_name}")
        logger.info(f"ë‚ ì”¨: {weather_info.get('weather', 'N/A')}")
        
        # í†µí•© í‚¤ì›Œë“œ ìƒì„± (AI íŠ¸ë Œë“œ + ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ)
        unified_keywords = []
        
        # 1. AI íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì¶”ê°€
        if context.get("ai_trends"):
            unified_keywords.extend(context["ai_trends"][:10])  # ìƒìœ„ 10ê°œ
            logger.info(f"AI íŠ¸ë Œë“œ í‚¤ì›Œë“œ {len(context['ai_trends'][:10])}ê°œ ì¶”ê°€")
        
        # 2. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í‚¤ì›Œë“œ ìƒì„±
        context_keywords = await self._generate_context_keywords(context)
        if context_keywords:
            unified_keywords.extend(context_keywords)
            logger.info(f"ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ {len(context_keywords)}ê°œ ì¶”ê°€")
        
        # 3. ì¤‘ë³µ ì œê±° ë° ì €ì¥
        context["unified_keywords"] = list(dict.fromkeys(unified_keywords))  # ìˆœì„œ ìœ ì§€ ì¤‘ë³µ ì œê±°
        logger.info(f"í†µí•© í‚¤ì›Œë“œ ìƒì„± ì™„ë£Œ: ì´ {len(context['unified_keywords'])}ê°œ")
        logger.info(f"í†µí•© í‚¤ì›Œë“œ: {context['unified_keywords']}")

        return context
    
    async def _get_holiday_from_db(self, target_date) -> Optional[str]:
        """DBì—ì„œ ê³µíœ´ì¼ ì •ë³´ ì¡°íšŒ"""
        try:
            with self.engine.connect() as conn:
                query = text("""
                    SELECT holiday_name 
                    FROM TAIHOLIDAYS 
                    WHERE holiday_date = :target_date
                """)
                result = conn.execute(query, {"target_date": target_date})
                row = result.fetchone()
                
                if row:
                    holiday_name = row[0]
                    logger.info(f"ê³µíœ´ì¼ ì¡°íšŒ ì„±ê³µ: {target_date} -> {holiday_name}")
                    return holiday_name
                else:
                    return None
        except Exception as e:
            logger.error(f"ê³µíœ´ì¼ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def _get_season(self, month: int) -> str:
        """ê³„ì ˆ ì •ë³´ ë°˜í™˜"""
        if month in [12, 1, 2]:
            return "ê²¨ìš¸"
        elif month in [3, 4, 5]:
            return "ë´„"
        elif month in [6, 7, 8]:
            return "ì—¬ë¦„"
        else:
            return "ê°€ì„"
    
    def _get_time_slot(self, dt: datetime) -> str:
        """ì‹œê°„ëŒ€ ì •ë³´ ë°˜í™˜"""
        hour = dt.hour
        if 6 <= hour < 12:
            return "ì˜¤ì „"
        elif 12 <= hour < 18:
            return "ì˜¤í›„"
        elif 18 <= hour < 24:
            return "ì €ë…"
        else:
            return "ìƒˆë²½"

    async def _classify_keywords_with_langchain(self, context: Dict[str, Any]) -> Dict[str, List[str]]:
        """LangChainì„ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ë¶„ë¥˜"""
        
        # ëª¨ë“  í‚¤ì›Œë“œ ìˆ˜ì§‘
        all_keywords = []
        
        # ë‚ ì”¨ í‚¤ì›Œë“œ
        if context["weather"].get("weather"):
            all_keywords.append(context["weather"]["weather"])
        
        # ì‹œê°„/ë‚ ì§œ í‚¤ì›Œë“œ
        all_keywords.extend([context["time_slot"], context["day_type"], context["season"]])
        
        # AI ìƒì„± íŠ¸ë Œë“œ ì¶”ê°€! (ë‚ ì”¨/ì‹œê°„ ê¸°ë°˜ íŠ¸ë Œë“œ)
        if "ai_trends" in context and context["ai_trends"]:
            all_keywords.extend(context["ai_trends"][:10])  # ìƒìœ„ 10ê°œë§Œ í¬í•¨
            logger.info(f"AI íŠ¸ë Œë“œ í‚¤ì›Œë“œ {len(context['ai_trends'][:10])}ê°œ ì¶”ê°€ë¨")

        # ìˆ˜ì§‘ëœ í‚¤ì›Œë“œë“¤ ë¡œê·¸ ì¶œë ¥
        logger.info(f"í‚¤ì›Œë“œ ë¶„ë¥˜ ì‹œì‘ - ì´ {len(all_keywords)}ê°œ í‚¤ì›Œë“œ: {all_keywords}")

        # LangChain í”„ë¡¬í”„íŠ¸
        classification_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ í™ˆì‡¼í•‘ ë°©ì†¡ í¸ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ í‚¤ì›Œë“œë“¤ì„ ë‹¤ìŒ ë‘ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

1. category_keywords: ìƒí’ˆ ì¹´í…Œê³ ë¦¬ì™€ ì—°ê´€ëœ í‚¤ì›Œë“œ (ì˜ˆ: íë¦°ë‚ ì”¨, ìº í•‘, ê±´ê°•ì‹í’ˆ, ê²¨ìš¸)
2. product_keywords: íŠ¹ì • ìƒí’ˆì„ ì§€ì¹­í•˜ëŠ” í‚¤ì›Œë“œ (ì˜ˆ: ì•„ì´í°, ë¼ë¶€ë¶€, ì •ê´€ì¥)

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""),
            ("human", "í‚¤ì›Œë“œ ëª©ë¡: {keywords}")
        ])
         
        chain = classification_prompt | self.llm | JsonOutputParser()
        
        try:
            result = await chain.ainvoke({"keywords": ", ".join(all_keywords)})
            logger.info(f"í‚¤ì›Œë“œ ë¶„ë¥˜ ì™„ë£Œ: ì¹´í…Œê³ ë¦¬ {len(result.get('category_keywords', []))}ê°œ, ìƒí’ˆ {len(result.get('product_keywords', []))}ê°œ")
            logger.info(f"ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ: {result.get('category_keywords', [])}")
            logger.info(f"ë¶„ë¥˜ëœ ìƒí’ˆ í‚¤ì›Œë“œ: {result.get('product_keywords', [])}")
            return result
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            # OpenAI API í• ë‹¹ëŸ‰ ì†Œì§„ ë˜ëŠ” API ì˜¤ë¥˜ ì‹œ ì˜ˆì™¸ ë°œìƒ
            if "insufficient_quota" in str(e) or "429" in str(e):
                raise Exception(f"AI ì„œë¹„ìŠ¤ ì¼ì‹œ ì¤‘ë‹¨ - OpenAI API í• ë‹¹ëŸ‰ ì†Œì§„: {e}")
            elif "api" in str(e).lower() or "openai" in str(e).lower():
                raise Exception(f"AI ì„œë¹„ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
            else:
                # ê¸°íƒ€ ì˜¤ë¥˜ëŠ” í´ë°± ë¡œì§ ì‚¬ìš©
                return {
                    "category_keywords": all_keywords[:10],
                    "product_keywords": []
                }
    
    async def _execute_unified_search(self, context: Dict[str, Any], unified_keywords: List[str]) -> Dict[str, Any]:
        """í†µí•© ê²€ìƒ‰: 1íšŒ Qdrant ê²€ìƒ‰ìœ¼ë¡œ ì§ì ‘ë§¤ì¹­/ì¹´í…Œê³ ë¦¬ ìƒí’ˆ ë¶„ë¥˜"""
        
        print(f"=== [DEBUG Unified Search] ì‹œì‘, keywords: {len(unified_keywords)}ê°œ ===")
        
        if not unified_keywords:
            logger.warning("í†µí•© í‚¤ì›Œë“œ ì—†ìŒ - ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            return {"direct_products": [], "category_groups": {}}
        
        query = " ".join(unified_keywords)
        print(f"=== [DEBUG Unified Search] Qdrant ê²€ìƒ‰ ì¿¼ë¦¬: '{query}' ===")
        
        try:
            # Qdrant í†µí•© ê²€ìƒ‰ (1íšŒ)
            all_results = self.product_embedder.search_products(
                trend_keywords=[query],
                top_k=30,
                score_threshold=0.3,
                only_ready_products=True
            )
            print(f"=== [DEBUG Unified Search] ê²€ìƒ‰ ê²°ê³¼: {len(all_results)}ê°œ ìƒí’ˆ ===")
            
            # ìœ ì‚¬ë„ ê¸°ë°˜ ë¶„ë¥˜
            direct_products = []      # ê³ ìœ ì‚¬ë„: ì§ì ‘ ì¶”ì²œ
            category_groups = {}      # ì¤‘ìœ ì‚¬ë„: ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë£¹
            
            # ìœ ì‚¬ë„ ì„ê³„ê°’
            HIGH_SIMILARITY_THRESHOLD = 0.7
            
            for product in all_results:
                similarity = product.get("similarity_score", 0)
                category = product.get("category_main", "ê¸°íƒ€")
                
                # ê³ ìœ ì‚¬ë„ ìƒí’ˆ: ì§ì ‘ ë§¤ì¹­ (XGBoost ê±´ë„ˆë›°ê¸° í›„ë³´)
                if similarity >= HIGH_SIMILARITY_THRESHOLD:
                    # ë³´ì™„: ì•ˆì „ì¥ì¹˜ - ë°©ì†¡í…Œì´í”„ í™•ì¸
                    if product.get("tape_code") and product.get("tape_name"):
                        direct_products.append({
                            **product,
                            "source": "direct_match",
                            "similarity_score": similarity
                        })
                        print(f"  - ì§ì ‘ë§¤ì¹­: {product.get('product_name')} (ìœ ì‚¬ë„: {similarity:.2f})")
                
                # ì¤‘ìœ ì‚¬ë„: ì¹´í…Œê³ ë¦¬ ê·¸ë£¹í•‘
                if category not in category_groups:
                    category_groups[category] = []
                category_groups[category].append(product)
            
            print(f"=== [DEBUG Unified Search] ì§ì ‘ë§¤ì¹­: {len(direct_products)}ê°œ, ì¹´í…Œê³ ë¦¬: {len(category_groups)}ê°œ ===")
            
            return {
                "direct_products": direct_products,
                "category_groups": category_groups
            }
            
        except Exception as e:
            logger.error(f"í†µí•© ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {"direct_products": [], "category_groups": {}}
    
    async def _execute_track_a(self, context: Dict[str, Any], category_keywords: List[str]) -> Dict[str, Any]:
        """Track A: ìœ ë§ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°"""
        
        print(f"=== [DEBUG Track A] ì‹œì‘, category_keywords: {category_keywords} ===")
        if not category_keywords:
            print("=== [DEBUG Track A] category_keywordsê°€ ë¹„ì–´ìˆìŒ ===")
            return {"categories": [], "scores": {}}
        
        # RAG ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
        query = " ".join(category_keywords)
        print(f"=== [DEBUG Track A] Qdrant ê²€ìƒ‰ ì¿¼ë¦¬: '{query}' ===")
        
        try:
            # Qdrantì—ì„œ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ (ë°©ì†¡ í…Œì´í”„ ì¤€ë¹„ ì™„ë£Œ ìƒí’ˆë§Œ)
            similar_products = self.product_embedder.search_products(
                trend_keywords=[query],
                top_k=30,  # í†µí•© ê²€ìƒ‰ê³¼ ë™ì¼í•˜ê²Œ 30ìœ¼ë¡œ ì„¤ì •
                score_threshold=0.3,
                only_ready_products=True
            )
            print(f"=== [DEBUG Track A] Qdrant ê²€ìƒ‰ ê²°ê³¼: {len(similar_products)}ê°œ ìƒí’ˆ ===")
            if len(similar_products) > 0:
                print(f"=== [DEBUG Track A] ì²« ë²ˆì§¸ ìƒí’ˆ ì˜ˆì‹œ: {similar_products[0]} ===")
            
            # ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë£¹í•‘
            category_scores = {}
            for product in similar_products:
                category = product.get('category_main', 'Unknown')
                score = product.get('similarity_score', 0)
                
                if category not in category_scores:
                    category_scores[category] = []
                category_scores[category].append(score)
            
            print(f"=== [DEBUG Track A] ì¹´í…Œê³ ë¦¬ ê·¸ë£¹í•‘ ì™„ë£Œ, ì´ {len(category_scores)} ì¹´í…Œê³ ë¦¬: {list(category_scores.keys())} ===")
            
            # Qdrant ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì „ì²´ ì¹´í…Œê³ ë¦¬ ì¡°íšŒ
            if len(category_scores) == 0:
                print("=== [DEBUG Track A] Qdrant ê²°ê³¼ ì—†ìŒ, PostgreSQLì—ì„œ ì „ì²´ ì¹´í…Œê³ ë¦¬ ì¡°íšŒ ===")
                all_categories = await self._get_all_categories_from_db()
                print(f"=== [DEBUG Track A] ì „ì²´ ì¹´í…Œê³ ë¦¬ {len(all_categories)}ê°œ ë°œê²¬: {all_categories} ===")
                # ê¸°ë³¸ ì ìˆ˜ ë¶€ì—¬
                for category in all_categories:
                    category_scores[category] = [0.5]  # ê¸°ë³¸ ìœ ì‚¬ë„ ì ìˆ˜
            
            # ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ì ìˆ˜ ê³„ì‚° ë° XGBoost ì˜ˆì¸¡
            promising_categories = []
            broadcast_dt = datetime.fromisoformat(context["broadcast_time"].replace('Z', '+00:00'))
            
            print(f"=== [DEBUG Track A] XGBoost ë§¤ì¶œ ì˜ˆì¸¡ ì‹œì‘ ===")
            for category, scores in category_scores.items():
                print(f"=== [DEBUG Track A] ì¹´í…Œê³ ë¦¬ '{category}' XGBoost ì˜ˆì¸¡ ì¤‘... ===")
                avg_score = sum(scores) / len(scores)
                
                # XGBoostë¡œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ì˜ˆìƒ ë§¤ì¶œ ì˜ˆì¸¡
                predicted_sales = await self._predict_category_sales(category, broadcast_dt)
                
                # ìµœì¢… ì ìˆ˜ = RAG ì ìˆ˜ * ì˜ˆìƒ ë§¤ì¶œ
                final_score = avg_score * (predicted_sales / 1000000)  # ë°±ë§Œì› ë‹¨ìœ„ë¡œ ì •ê·œí™”
                
                promising_categories.append({
                    "category": category,
                    "rag_score": avg_score,
                    "predicted_sales": predicted_sales,
                    "final_score": final_score,
                    "reason": "AI ì¶”ì²œ ìœ ë§ ì¹´í…Œê³ ë¦¬"
                })
            
            print(f"=== [DEBUG Track A] XGBoost ì˜ˆì¸¡ ì™„ë£Œ, ì´ {len(promising_categories)} ì¹´í…Œê³ ë¦¬ ===")
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            promising_categories.sort(key=lambda x: x["final_score"], reverse=True)
            
            # RecommendedCategory ê°ì²´ë¡œ ë³€í™˜
            result = []
            for i, cat in enumerate(promising_categories[:5]):
                result.append(RecommendedCategory(
                    rank=i+1,
                    name=cat["category"],
                    reason=cat["reason"],
                    predictedSales=f"{int(cat['predicted_sales']/10000)}ë§Œì›"  # ë§Œì› ë‹¨ìœ„
                ))
            
            print(f"=== [DEBUG Track A] ìµœì¢… ê²°ê³¼: {len(result)} ì¹´í…Œê³ ë¦¬ ===")
            logger.info(f"Track A: ìœ ë§ ì¹´í…Œê³ ë¦¬ {len(result)}ê°œ ë°œê²¬")
            return {"categories": result, "scores": category_scores}
            
        except Exception as e:
            logger.error(f"Track A ì˜¤ë¥˜: {e}")
            return {"categories": [], "scores": {}}
    
    async def _generate_context_keywords(self, context: Dict[str, Any]) -> List[str]:
        """ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LangChainìœ¼ë¡œ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±"""
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ (ì•ˆì „í•˜ê²Œ)
        weather_info = context.get("weather", {})
        logger.info(f"weather_info type: {type(weather_info)}, value: {weather_info}")
        
        if isinstance(weather_info, dict):
            weather = weather_info.get("weather", "ë§‘ìŒ")
            temperature = weather_info.get("temperature", 20)
        else:
            logger.warning(f"weather_info is not dict: {weather_info}")
            weather = "ë§‘ìŒ"
            temperature = 20
        
        time_slot = context.get("time_slot", "ì €ë…")
        season = context.get("season", "ë´„")
        day_type = context.get("day_type", "í‰ì¼")
        holiday_name = context.get("holiday_name")  # ê³µíœ´ì¼ ì •ë³´
        
        logger.info(f"ì¶”ì¶œëœ ì •ë³´ - weather: {weather}, temp: {temperature}, time_slot: {time_slot}, season: {season}, day_type: {day_type}, holiday: {holiday_name}")
        
        # LangChain í”„ë¡¬í”„íŠ¸
        keyword_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ í™ˆì‡¼í•‘ ë°©ì†¡ í¸ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬, í•´ë‹¹ ì‹œê°„/ë‚ ì”¨/ìƒí™©ì— ì í•©í•œ ìƒí’ˆ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ì˜ˆì‹œ:
- ë‚ ì”¨ê°€ 'ë¹„'ì´ê³  ì €ë… ì‹œê°„ â†’ "ìš°ì‚°", "ë°©ìˆ˜", "ì‹¤ë‚´í™œë™", "ë”°ëœ»í•œìŒì‹", "ì§‘ì½•", "ìš”ë¦¬ë„êµ¬"
- ë‚ ì”¨ê°€ 'ë§‘ìŒ'ì´ê³  ì˜¤í›„ ì‹œê°„ â†’ "ì•¼ì™¸í™œë™", "ìš´ë™", "ìº í•‘", "ë ˆì €", "ìì™¸ì„ ì°¨ë‹¨"
- ê²¨ìš¸ì²  ì €ë… ì‹œê°„ â†’ "ë‚œë°©", "ë³´ì˜¨", "ë”°ëœ»í•œ", "ê²¨ìš¸ì˜ë¥˜", "ì˜¨ì—´", "ì°œì§ˆ"
- í¬ë¦¬ìŠ¤ë§ˆìŠ¤ â†’ "ì„ ë¬¼", "íŒŒí‹°", "ì¼€ì´í¬", "ì¥ì‹", "ê°€ì¡±ëª¨ì„", "ì—°ë§ì„ ë¬¼"
- ì¶”ì„ â†’ "ì„ ë¬¼ì„¸íŠ¸", "í•œë³µ", "ì†¡í¸", "ê·€ì„±", "ëª…ì ˆìŒì‹", "ì°¨ë¡€ìƒ"

**ì¤‘ìš”: ê³µíœ´ì¼ì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ê³µíœ´ì¼ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ìš°ì„ ì ìœ¼ë¡œ í¬í•¨í•˜ì„¸ìš”!**

5-10ê°œì˜ í‚¤ì›Œë“œë¥¼ JSON ë°°ì—´ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”."""),
            ("human", """ë‚ ì”¨: {weather}
ê¸°ì˜¨: {temperature}ë„
ì‹œê°„ëŒ€: {time_slot}
ê³„ì ˆ: {season}
ìš”ì¼ íƒ€ì…: {day_type}
ê³µíœ´ì¼: {holiday_name}

ìœ„ ìƒí™©ì— ì í•©í•œ ìƒí’ˆ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ê³µíœ´ì¼ì´ ìˆë‹¤ë©´ ê³µíœ´ì¼ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”!""")
        ])
        
        chain = keyword_prompt | self.llm | JsonOutputParser()
        
        try:
            # í”„ë¡¬í”„íŠ¸ ë¡œê¹… (ëˆˆì— ë„ê²Œ)
            prompt_vars = {
                "weather": weather,
                "temperature": temperature,
                "time_slot": time_slot,
                "season": season,
                "day_type": day_type,
                "holiday_name": holiday_name if holiday_name else "ì—†ìŒ"
            }
            print("=" * 80)
            print("[LLM í”„ë¡¬í”„íŠ¸] ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ìƒì„±")
            print("=" * 80)
            print(f"ë³€ìˆ˜: {prompt_vars}")
            print("=" * 80)
            logger.info(f"[LLM í”„ë¡¬í”„íŠ¸] ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ìƒì„± - ë³€ìˆ˜: {prompt_vars}")
            
            result = await chain.ainvoke({
                "weather": weather,
                "temperature": temperature,
                "time_slot": time_slot,
                "season": season,
                "day_type": day_type,
                "holiday_name": holiday_name if holiday_name else "ì—†ìŒ"
            })
            # resultê°€ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆê³  ë”•ì…”ë„ˆë¦¬ì¼ ìˆ˜ë„ ìˆìŒ
            if isinstance(result, list):
                keywords = result
            elif isinstance(result, dict):
                keywords = result.get("keywords", [])
            else:
                keywords = []
            
            logger.info(f"ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í‚¤ì›Œë“œ ìƒì„± ì™„ë£Œ: {keywords}")
            logger.info(f"ë°˜í™˜í•  í‚¤ì›Œë“œ ê°œìˆ˜: {len(keywords)}")
            return keywords
        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(f"ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")
            # í´ë°±: ì‹œê°„ëŒ€/ê³„ì ˆ ê¸°ë°˜ ì‹¤ìš©ì  í‚¤ì›Œë“œ
            fallback_keywords = []
            
            # ì‹œê°„ëŒ€ë³„ í‚¤ì›Œë“œ
            if time_slot == "ì €ë…":
                fallback_keywords.extend(["ì €ë…ì‹ì‚¬", "ì‹¤ë‚´í™œë™", "íœ´ì‹", "ê°€ì¡±ì‹œê°„"])
            elif time_slot == "ì˜¤ì „":
                fallback_keywords.extend(["ì•„ì¹¨", "ì¶œê·¼", "í™œë ¥", "ê±´ê°•"])
            elif time_slot == "ì˜¤í›„":
                fallback_keywords.extend(["ì ì‹¬", "ì•¼ì™¸í™œë™", "ìš´ë™", "ì‡¼í•‘"])
            else:
                fallback_keywords.extend(["ë°¤", "ìˆ˜ë©´", "íœ´ì‹"])
            
            # ê³„ì ˆë³„ í‚¤ì›Œë“œ
            if season == "ê²¨ìš¸":
                fallback_keywords.extend(["ë”°ëœ»í•œ", "ë³´ì˜¨", "ë‚œë°©"])
            elif season == "ì—¬ë¦„":
                fallback_keywords.extend(["ì‹œì›í•œ", "ëƒ‰ë°©", "íœ´ê°€"])
            elif season == "ë´„":
                fallback_keywords.extend(["ì‹ ì„ í•œ", "ì•¼ì™¸", "ê½ƒ"])
            else:
                fallback_keywords.extend(["ê°€ì„", "ê±´ê°•", "í™˜ì ˆê¸°"])
            
            logger.info(f"í´ë°± í‚¤ì›Œë“œ ì‚¬ìš©: {fallback_keywords}")
            logger.info(f"í´ë°± í‚¤ì›Œë“œ ê°œìˆ˜: {len(fallback_keywords)}")
            return fallback_keywords
    
    async def _execute_track_b(self, context: Dict[str, Any], product_keywords: List[str]) -> Dict[str, Any]:
        """Track B: ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ìƒí’ˆ ì°¾ê¸° (ë‚ ì”¨/ì‹œê°„ëŒ€ ê¸°ë°˜)"""
        
        print(f"=== [DEBUG Track B] ì‹œì‘, product_keywords: {product_keywords} ===")
        
        generated_keywords = []  # ìƒì„±ëœ í‚¤ì›Œë“œ ì €ì¥
        
        # 1. íŠ¸ë Œë“œ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ìƒì„±
        if not product_keywords:
            logger.info("Track B: íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì—†ìŒ â†’ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í‚¤ì›Œë“œ ìƒì„±")
            product_keywords = await self._generate_context_keywords(context)
            generated_keywords = product_keywords  # ìƒì„±ëœ í‚¤ì›Œë“œ ë³´ê´€
            print(f"=== [DEBUG Track B] ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ: {product_keywords} ===")
            logger.info(f"ìƒì„±ëœ í‚¤ì›Œë“œ: {product_keywords}, íƒ€ì…: {type(product_keywords)}")
        
        if not product_keywords:
            logger.info("Track B: í‚¤ì›Œë“œ ì—†ìŒ â†’ ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            return {"products": [], "trend_scores": {}, "generated_keywords": []}
        
        # 2. ìƒì„±ëœ í‚¤ì›Œë“œë¡œ ìƒí’ˆ ê²€ìƒ‰
        query = " ".join(product_keywords)
        print(f"=== [DEBUG Track B] Qdrant ê²€ìƒ‰ ì¿¼ë¦¬: '{query}' ===")
        
        try:
            # Qdrantì—ì„œ ìƒí’ˆ ê²€ìƒ‰ (ë°©ì†¡ í…Œì´í”„ ì¤€ë¹„ ì™„ë£Œ ìƒí’ˆë§Œ)
            similar_products = self.product_embedder.search_products(
                trend_keywords=[query],
                top_k=30,  # í†µí•© ê²€ìƒ‰ê³¼ ë™ì¼í•˜ê²Œ 30ìœ¼ë¡œ ì„¤ì •
                score_threshold=0.3
            )
            
            print(f"=== [DEBUG Track B] Qdrant ê²€ìƒ‰ ê²°ê³¼: {len(similar_products)}ê°œ ===")
            
            if similar_products:
                trend_scores = {p["product_code"]: p.get("score", 0.5) for p in similar_products}
                logger.info(f"Track B ì™„ë£Œ: {len(similar_products)}ê°œ ìƒí’ˆ ë°œê²¬")
                return {"products": similar_products, "trend_scores": trend_scores, "generated_keywords": generated_keywords}
            else:
                logger.info("Track B: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return {"products": [], "trend_scores": {}, "generated_keywords": generated_keywords}
                
        except Exception as e:
            logger.error(f"Track B ì˜¤ë¥˜: {e}")
            return {"products": [], "trend_scores": {}, "generated_keywords": []}
    
    async def _generate_unified_candidates(
        self,
        search_result: Dict[str, Any],
        context: Dict[str, Any],
        max_trend_match: int = 3,  # ìœ ì‚¬ë„ ê¸°ë°˜ ìµœëŒ€ ê°œìˆ˜
        max_sales_prediction: int = 10  # ë§¤ì¶œì˜ˆì¸¡ ê¸°ë°˜ ìµœëŒ€ ê°œìˆ˜
    ) -> tuple[List[Dict[str, Any]], Dict[str, Any], List[RecommendedCategory]]:
        """í†µí•© í›„ë³´êµ° ìƒì„± - ëª¨ë“  ìƒí’ˆ XGBoost ì˜ˆì¸¡ í›„ ê°€ì¤‘ì¹˜ ì¡°ì •"""
        
        candidates = []
        seen_products = set()
        
        print(f"=== [DEBUG Unified Candidates] í›„ë³´êµ° ìƒì„± ì‹œì‘ (ëª©í‘œ: ìµœëŒ€ {max_trend_match + max_sales_prediction}ê°œ) ===")
        
        # 1. ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ í†µí•©
        all_products = []
        all_products.extend(search_result["direct_products"])  # ê³ ìœ ì‚¬ë„ ìƒí’ˆ
        
        # ì¹´í…Œê³ ë¦¬ ê·¸ë£¹ì˜ ëª¨ë“  ìƒí’ˆë„ ì¶”ê°€
        for category, products in search_result["category_groups"].items():
            all_products.extend(products)
        
        print(f"=== [DEBUG] í†µí•©ëœ ìƒí’ˆ ìˆ˜: {len(all_products)}ê°œ ===")
        
        # 2. ì¤‘ë³µ ì œê±° (ìƒí’ˆì½”ë“œ + ì†Œë¶„ë¥˜)
        unique_products = {}
        seen_sub_categories = set()
        
        for product in all_products:
            product_code = product.get("product_code")
            category_sub = product.get("category_sub", "")
            
            # ìƒí’ˆì½”ë“œ ì¤‘ë³µ ì²´í¬
            if product_code in unique_products:
                continue
            
            # ì†Œë¶„ë¥˜ ì¤‘ë³µ ì²´í¬ (ë‹¤ì–‘ì„± ë³´ì¥)
            if category_sub and category_sub in seen_sub_categories:
                logger.info(f"ì†Œë¶„ë¥˜ ì¤‘ë³µ ì œì™¸: {product.get('product_name', '')[:30]} (ì†Œë¶„ë¥˜: {category_sub})")
                continue
            
            # í†µê³¼í•œ ê²½ìš° ì¶”ê°€
            unique_products[product_code] = product
            if category_sub:
                seen_sub_categories.add(category_sub)
        
        print(f"=== [DEBUG] ì¤‘ë³µ ì œê±° í›„: {len(unique_products)}ê°œ (ì†Œë¶„ë¥˜ ë‹¤ì–‘ì„± ë³´ì¥) ===")
        
        # 3. ë°°ì¹˜ ì˜ˆì¸¡ ì¤€ë¹„ (ìƒìœ„ 30ê°œë§Œ)
        products_list = list(unique_products.values())[:30]
        print(f"=== [DEBUG] ë°°ì¹˜ ì˜ˆì¸¡ ëŒ€ìƒ: {len(products_list)}ê°œ ===")
        
        # 4. ë°°ì¹˜ XGBoost ì˜ˆì¸¡ (í•œ ë²ˆì— ì²˜ë¦¬)
        predicted_sales_list = await self._predict_products_sales_batch(products_list, context)
        
        # 5. ì˜ˆì¸¡ ê²°ê³¼ì™€ ìƒí’ˆ ë§¤ì¹­ + ì ìˆ˜ ê³„ì‚°
        for i, product in enumerate(products_list):
            similarity = product.get("similarity_score", 0.5)
            predicted_sales = predicted_sales_list[i]
            
            # ì ìˆ˜ ê³„ì‚° (ìœ ì‚¬ë„ vs ë§¤ì¶œ ê°€ì¤‘ì¹˜ ì¡°ì •)
            if similarity >= 0.7:
                # ê³ ìœ ì‚¬ë„: ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜ ë†’ì„
                final_score = (
                    similarity * 0.7 +  # ìœ ì‚¬ë„ 70%
                    (predicted_sales / 100000000) * 0.3  # ë§¤ì¶œ 30% (ì •ê·œí™”: 1ì–µ ê¸°ì¤€)
                )
                source = "trend_match"
                print(f"  [ê³ ìœ ì‚¬ë„] {product.get('product_name')[:20]}: ìœ ì‚¬ë„={similarity:.2f}, ë§¤ì¶œ={predicted_sales/10000:.0f}ë§Œì›, ì ìˆ˜={final_score:.3f}")
            else:
                # ì €ìœ ì‚¬ë„: ë§¤ì¶œ ê°€ì¤‘ì¹˜ ë†’ì„
                final_score = (
                    similarity * 0.3 +  # ìœ ì‚¬ë„ 30%
                    (predicted_sales / 100000000) * 0.7  # ë§¤ì¶œ 70%
                )
                source = "sales_prediction"
                print(f"  [ì €ìœ ì‚¬ë„] {product.get('product_name')[:20]}: ìœ ì‚¬ë„={similarity:.2f}, ë§¤ì¶œ={predicted_sales/10000:.0f}ë§Œì›, ì ìˆ˜={final_score:.3f}")
            
            candidates.append({
                "product": product,
                "source": source,
                "similarity_score": similarity,
                "predicted_sales": predicted_sales,
                "final_score": final_score
            })
        
        # 4. ì ìˆ˜ìˆœ ì •ë ¬
        candidates.sort(key=lambda x: x["final_score"], reverse=True)
        
        print(f"=== [DEBUG] ì´ {len(candidates)}ê°œ í›„ë³´ ìƒì„± ì™„ë£Œ, ì ìˆ˜ìˆœ ì •ë ¬ë¨ ===")
        
        # 5. ìƒìœ„ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (API ì‘ë‹µìš©)
        category_scores = {}
        top_categories = []
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ì ìˆ˜ ê³„ì‚°
        category_sales = {}
        for candidate in candidates:
            category = candidate["product"].get("product_lgroup", "ê¸°íƒ€")
            if category not in category_sales:
                category_sales[category] = []
            category_sales[category].append(candidate["predicted_sales"])
        
        # ìƒìœ„ 3ê°œ ì¹´í…Œê³ ë¦¬
        sorted_categories = sorted(
            category_sales.items(),
            key=lambda x: sum(x[1]) / len(x[1]),  # í‰ê·  ë§¤ì¶œ
            reverse=True
        )[:3]
        
        for i, (category, sales_list) in enumerate(sorted_categories):
            avg_sales = sum(sales_list) / len(sales_list)
            category_scores[category] = {"predicted_sales": avg_sales}
            top_categories.append(RecommendedCategory(
                rank=i+1,
                name=category,
                reason="AI ì¶”ì²œ ìœ ë§ ì¹´í…Œê³ ë¦¬",
                predictedSales=f"{int(avg_sales/10000)}ë§Œì›"
            ))
        
        return candidates, category_scores, top_categories
    
    async def _predict_categories_with_xgboost(
        self, 
        category_groups: Dict[str, List[Dict]], 
        context: Dict[str, Any]
    ) -> Dict[str, Dict[str, float]]:
        """ì¹´í…Œê³ ë¦¬ë³„ XGBoost ë§¤ì¶œ ì˜ˆì¸¡"""
        
        category_scores = {}
        broadcast_dt = context["broadcast_dt"]
        
        for category, products in category_groups.items():
            if not products:
                continue
            
            try:
                # ëŒ€í‘œ ìƒí’ˆìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ë§¤ì¶œ ì˜ˆì¸¡
                representative_product = products[0]
                predicted_sales = await self._predict_product_sales(representative_product, context)
                
                # ì¹´í…Œê³ ë¦¬ ë‚´ ìƒí’ˆ ìˆ˜ë¡œ ë³´ì •
                adjusted_sales = predicted_sales * min(len(products) / 5, 2.0)
                
                category_scores[category] = {
                    "predicted_sales": adjusted_sales,
                    "product_count": len(products),
                    "avg_similarity": sum(p.get("similarity_score", 0) for p in products) / len(products)
                }
                
                print(f"  - ì¹´í…Œê³ ë¦¬ '{category}': {int(adjusted_sales/10000)}ë§Œì› (ìƒí’ˆ: {len(products)}ê°œ)")
                
            except Exception as e:
                logger.error(f"ì¹´í…Œê³ ë¦¬ '{category}' ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                category_scores[category] = {
                    "predicted_sales": 10000000,  # ê¸°ë³¸ê°’ 1000ë§Œì›
                    "product_count": len(products),
                    "avg_similarity": 0.4
                }
        
        return category_scores
    
    async def _generate_candidates(self, promising_categories: List[RecommendedCategory], trend_products: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """í›„ë³´êµ° ìƒì„± ë° í†µí•© (ë ˆê±°ì‹œ, ì‚¬ìš© ì•ˆ í•¨)"""
        candidates = []
        
        # ìœ ë§ ì¹´í…Œê³ ë¦¬ì—ì„œ ì—ì´ìŠ¤ ìƒí’ˆ ì„ ë°œ
        for category in promising_categories[:3]:
            ace_products = await self._get_ace_products_from_category(category.name, 5)
            
            for product in ace_products:
                candidates.append({
                    "product": product,
                    "source": "category",
                    "base_score": product.get("predicted_sales_score", 0.5),
                    "trend_boost": 1.0
                })
        
        return candidates
    
    async def _rank_final_candidates(self, candidates: List[Dict[str, Any]], category_scores: Dict[str, Any], context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ìµœì¢… ë­í‚¹ ê³„ì‚° - ì´ë¯¸ ì •ë ¬ëœ candidates ë°˜í™˜ (XGBoost ì˜ˆì¸¡ ì™„ë£Œë¨)"""
        
        print(f"=== [DEBUG _rank_final_candidates] ì´ë¯¸ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬ëœ {len(candidates)}ê°œ í›„ë³´ ìˆ˜ì‹  ===")
        
        # ì´ë¯¸ _generate_unified_candidatesì—ì„œ final_score ê³„ì‚° ë° ì •ë ¬ ì™„ë£Œ
        # ì—¬ê¸°ì„œëŠ” ì¶”ê°€ ì²˜ë¦¬ ì—†ì´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        
        for i, candidate in enumerate(candidates[:5]):
            print(f"  {i+1}ìœ„: {candidate['product'].get('product_name')[:25]} (ì ìˆ˜: {candidate['final_score']:.3f}, íƒ€ì…: {candidate['source']})")
        
        return candidates
    
    def _calculate_competition_penalty(self, product: Dict[str, Any], all_candidates: List[Dict[str, Any]]) -> float:
        """ê²½ìŸ í˜ë„í‹° ì ìˆ˜ ê³„ì‚°"""
        category = product.get("category_main", "")
        same_category_count = sum(1 for c in all_candidates if c["product"].get("category_main") == category)
        
        # ê°™ì€ ì¹´í…Œê³ ë¦¬ ìƒí’ˆì´ ë§ì„ìˆ˜ë¡ í˜ë„í‹°
        if same_category_count <= 2:
            return 0.0
        elif same_category_count <= 4:
            return 0.1
        else:
            return 0.2
    
    async def _format_response(self, ranked_products: List[Dict[str, Any]], top_categories: List[RecommendedCategory], context: Dict[str, Any] = None) -> BroadcastResponse:
        """API ì‘ë‹µ ìƒì„± (ë¹„ë™ê¸°)"""
        print(f"=== [DEBUG _format_response] context keys: {context.keys() if context else 'None'} ===")
        if context:
            print(f"=== [DEBUG _format_response] generated_keywords: {context.get('generated_keywords', [])} ===")
        recommendations = []
        
        for i, candidate in enumerate(ranked_products):
            product = candidate["product"]
            
            # LangChain ê¸°ë°˜ ë™ì  ê·¼ê±° ìƒì„± (ë¹„ë™ê¸°)
            reasoning_summary = await self._generate_dynamic_reason_with_langchain(
                candidate, 
                context or {"time_slot": "ì €ë…", "weather": {"weather": "í­ì—¼"}}
            )
            
            # ì¶”ì²œ íƒ€ì… ê²°ì •
            recommendation_type = candidate.get("source", "sales_prediction")
            
            recommendation = BroadcastRecommendation(
                rank=i+1,
                productInfo=ProductInfo(
                    productId=product.get("product_code", "Unknown"),
                    productName=product.get("product_name", "Unknown"),
                    category=product.get("category_main", "Unknown"),
                    price=product.get("price"),
                    tapeCode=product.get("tape_code"),
                    tapeName=product.get("tape_name")
                ),
                reasoning=Reasoning(
                    summary=reasoning_summary,
                    linkedCategories=[product.get("category_main", "Unknown")],
                    matchedKeywords=(
                        (context.get("generated_keywords", [])[:3] +  # ì‹œê°„ëŒ€ ë§¥ë½
                        context.get("ai_trends", [])[:2])            # AI íŠ¸ë Œë“œ
                    ) if context else []
                ),
                businessMetrics=BusinessMetrics(
                    pastAverageSales=f"{int(candidate['predicted_sales']/10000)}ë§Œì›",  # ë§Œì› ë‹¨ìœ„
                    marginRate=0.25,
                    stockLevel="High"
                ),
                recommendationType=recommendation_type  # ì¶”ì²œ íƒ€ì… ì¶”ê°€
            )
            recommendations.append(recommendation)
        
        return BroadcastResponse(
            requestTime="",  # ë©”ì¸ì—ì„œ ì„¤ì •
            recommendedCategories=top_categories,
            recommendations=recommendations
        )
    
    def _generate_recommendation_reason(self, candidate: Dict[str, Any], context: Dict[str, Any] = None) -> str:
        """ê°œì„ ëœ ì¶”ì²œ ê·¼ê±° ìƒì„±"""
        product = candidate["product"]
        source = candidate["source"]
        trend_boost = candidate.get("trend_boost", 1.0)
        predicted_sales = candidate.get("predicted_sales", 0)
        final_score = candidate.get("final_score", 0)
        
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        category = product.get("category_main", "")
        product_name = product.get("product_name", "")
        trend_keyword = candidate.get("trend_keyword", "")
        tape_name = product.get("tape_name", "")
        
        # ì‹œê°„ëŒ€ ì •ë³´
        time_slot = context.get("time_slot", "") if context else ""
        weather = context.get("weather", {}).get("weather", "") if context else ""
        
        # ê·¼ê±° êµ¬ì„± ìš”ì†Œë“¤
        reasons = []
        
        # 1. íŠ¸ë Œë“œ ê´€ë ¨ ê·¼ê±°
        if source == "trend" and trend_keyword:
            if trend_boost > 1.3:
                reasons.append(f"'{trend_keyword}' íŠ¸ë Œë“œ ê¸‰ìƒìŠ¹ ë°˜ì˜")
            elif trend_boost > 1.1:
                reasons.append(f"'{trend_keyword}' íŠ¸ë Œë“œ ìƒìŠ¹ì„¸")
            else:
                reasons.append(f"'{trend_keyword}' í‚¤ì›Œë“œ ì—°ê´€ì„±")
        
        # 2. ì¹´í…Œê³ ë¦¬ ê´€ë ¨ ê·¼ê±°
        elif source == "category":
            reasons.append(f"{category} ì¹´í…Œê³ ë¦¬ ìœ ë§ ìƒí’ˆ")
        
        # 3. ë§¤ì¶œ ì˜ˆì¸¡ ê·¼ê±°
        if predicted_sales > 80000000:  # 8ì²œë§Œì› ì´ìƒ
            reasons.append("ë†’ì€ ë§¤ì¶œ ì˜ˆì¸¡")
        elif predicted_sales > 50000000:  # 5ì²œë§Œì› ì´ìƒ
            reasons.append("ì•ˆì •ì  ë§¤ì¶œ ì˜ˆì¸¡")
        
        # 4. ì‹œê°„ëŒ€ ì í•©ì„±
        if time_slot and weather:
            if time_slot == "ì €ë…" and category in ["ê±´ê°•ì‹í’ˆ", "í™”ì¥í’ˆ"]:
                reasons.append("ì €ë… ì‹œê°„ëŒ€ ìµœì ")
            elif time_slot == "ì˜¤í›„" and category in ["ê°€ì „ì œí’ˆ", "ìƒí™œìš©í’ˆ"]:
                reasons.append("ì˜¤í›„ ì‹œê°„ëŒ€ ì í•©")
            elif weather == "í­ì—¼" and category in ["ê°€ì „ì œí’ˆ"] and "ì„ í’ê¸°" in product_name:
                reasons.append("í­ì—¼ ë‚ ì”¨ ìµœì  ìƒí’ˆ")
        
        # 5. ë°©ì†¡í…Œì´í”„ ì •ë³´
        if tape_name:
            reasons.append("ë°©ì†¡í…Œì´í”„ ì¤€ë¹„ ì™„ë£Œ")
        
        # 6. AI ì‹ ë¢°ë„
        if final_score > 0.8:
            reasons.append("AI ë†’ì€ ì‹ ë¢°ë„")
        elif final_score > 0.6:
            reasons.append("AI ì¶”ì²œ ì í•©")
        
        # ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë©”ì‹œì§€
        if not reasons:
            reasons.append("ì¢…í•© ë¶„ì„ ê²°ê³¼ ì¶”ì²œ")
        
        # ìµœëŒ€ 3ê°œ ê·¼ê±°ë§Œ ì‚¬ìš©
        return " + ".join(reasons[:3])
    
    def _generate_diverse_reason_templates(self, candidate: Dict[str, Any], context: Dict[str, Any] = None) -> List[str]:
        """ë‹¤ì–‘í•œ ì¶”ì²œ ê·¼ê±° í…œí”Œë¦¿ ìƒì„±"""
        product = candidate["product"]
        source = candidate["source"]
        trend_boost = candidate.get("trend_boost", 1.0)
        predicted_sales = candidate.get("predicted_sales", 0)
        
        # ê¸°ë³¸ ì •ë³´
        category = product.get("category_main", "")
        product_name = product.get("product_name", "")
        trend_keyword = candidate.get("trend_keyword", "")
        
        templates = []
        
        # íŠ¸ë Œë“œ ê¸°ë°˜ í…œí”Œë¦¿ë“¤
        if source == "trend" and trend_keyword:
            trend_templates = [
                f"'{trend_keyword}' ê²€ìƒ‰ëŸ‰ ê¸‰ì¦ìœ¼ë¡œ ë†’ì€ ê´€ì‹¬ë„ ì˜ˆìƒ",
                f"ì‹¤ì‹œê°„ '{trend_keyword}' íŠ¸ë Œë“œ ë°˜ì˜í•œ íƒ€ì´ë° ìƒí’ˆ",
                f"'{trend_keyword}' í‚¤ì›Œë“œ ì—°ê´€ ìƒí’ˆìœ¼ë¡œ ì‹œì²­ì ê´€ì‹¬ ì§‘ì¤‘",
                f"íŠ¸ë Œë“œ '{trend_keyword}'ì™€ ì™„ë²½ ë§¤ì¹­ë˜ëŠ” ìµœì  ìƒí’ˆ",
                f"'{trend_keyword}' í™”ì œì„± í™œìš©í•œ ì‹œì˜ì ì ˆí•œ í¸ì„±"
            ]
            templates.extend(trend_templates)
        
        # ë§¤ì¶œ ì˜ˆì¸¡ ê¸°ë°˜ í…œí”Œë¦¿ë“¤
        sales_million = int(predicted_sales / 1000000)
        if sales_million > 80:
            sales_templates = [
                f"AI ì˜ˆì¸¡ ë§¤ì¶œ {sales_million}ë°±ë§Œì›ìœ¼ë¡œ ìµœê³  ìˆ˜ìµ ê¸°ëŒ€",
                f"ê³¼ê±° ë°ì´í„° ë¶„ì„ ê²°ê³¼ {sales_million}ë°±ë§Œì› ë§¤ì¶œ ì˜ˆìƒ",
                f"ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì˜ˆì¸¡ {sales_million}ë°±ë§Œì› ê³ ìˆ˜ìµ ìƒí’ˆ"
            ]
        elif sales_million > 50:
            sales_templates = [
                f"ì•ˆì •ì  {sales_million}ë°±ë§Œì› ë§¤ì¶œ ì˜ˆì¸¡ìœ¼ë¡œ ë¦¬ìŠ¤í¬ ìµœì†Œí™”",
                f"ê²€ì¦ëœ {sales_million}ë°±ë§Œì› ìˆ˜ìµ ëª¨ë¸ ìƒí’ˆ",
                f"ì˜ˆì¸¡ ë§¤ì¶œ {sales_million}ë°±ë§Œì›ìœ¼ë¡œ ì•ˆì „í•œ í¸ì„± ì„ íƒ"
            ]
        else:
            sales_templates = [
                "ë°ì´í„° ê¸°ë°˜ ë§¤ì¶œ ì˜ˆì¸¡ìœ¼ë¡œ ê²€ì¦ëœ ìƒí’ˆ",
                "AI ë¶„ì„ ê²°ê³¼ ìˆ˜ìµì„± í™•ì¸ëœ ì¶”ì²œ ìƒí’ˆ",
                "ê³¼ê±° ì„±ê³¼ ë°ì´í„° ê¸°ë°˜ ì„ ë³„ëœ ìƒí’ˆ"
            ]
        templates.extend(sales_templates)
        
        # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í…œí”Œë¦¿ë“¤
        category_templates = [
            f"{category} ë¶„ì•¼ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ê²€ì¦ ìƒí’ˆ",
            f"{category} ì¹´í…Œê³ ë¦¬ ë‚´ ê²½ìŸë ¥ 1ìœ„ ìƒí’ˆ",
            f"{category} ì‹œì¥ì—ì„œ ì…ì¦ëœ ì¸ê¸° ìƒí’ˆ",
            f"{category} ì „ë¬¸ ìƒí’ˆìœ¼ë¡œ íƒ€ê²Ÿ ì‹œì²­ì í™•ë³´",
            f"{category} ë¶„ì•¼ í”„ë¦¬ë¯¸ì—„ ë¸Œëœë“œ ìƒí’ˆ"
        ]
        templates.extend(category_templates)
        
        # ì‹œê°„ëŒ€/ìƒí™© ê¸°ë°˜ í…œí”Œë¦¿ë“¤
        if context:
            time_slot = context.get("time_slot", "")
            weather = context.get("weather", {}).get("weather", "")
            
            if time_slot == "ì €ë…":
                time_templates = [
                    "ì €ë… ì‹œê°„ëŒ€ ì‹œì²­ì íŠ¹ì„±ì— ìµœì í™”ëœ ìƒí’ˆ",
                    "í‡´ê·¼ í›„ ê´€ì‹¬ë„ ë†’ì€ ì €ë… íƒ€ì„ ë§ì¶¤ ìƒí’ˆ",
                    "ì €ë… ì‹œê°„ êµ¬ë§¤ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ì„ ì •"
                ]
                templates.extend(time_templates)
            
            if weather == "í­ì—¼":
                weather_templates = [
                    "í­ì—¼ íŠ¹ìˆ˜ ìˆ˜ìš” ê¸‰ì¦ ì˜ˆìƒ ìƒí’ˆ",
                    "ë¬´ë”ìœ„ í•´ê²°ì‚¬ë¡œ ì‹œì˜ì ì ˆí•œ í¸ì„±",
                    "í­ì—¼ ëŒ€ë¹„ í•„ìˆ˜ ì•„ì´í…œìœ¼ë¡œ êµ¬ë§¤ ìš•êµ¬ ìê·¹"
                ]
                templates.extend(weather_templates)
        
        # ë°©ì†¡í…Œì´í”„ ê¸°ë°˜ í…œí”Œë¦¿ë“¤
        tape_name = product.get("tape_name", "")
        if tape_name:
            tape_templates = [
                f"ì „ìš© ë°©ì†¡í…Œì´í”„ '{tape_name}' ì™„ë²½ ì¤€ë¹„ ì™„ë£Œ",
                f"ê²€ì¦ëœ ë°©ì†¡ ì½˜í…ì¸ ë¡œ ì‹œì²­ì ëª°ì…ë„ ê·¹ëŒ€í™”",
                f"ì „ë¬¸ ì œì‘ ë°©ì†¡í…Œì´í”„ë¡œ ìƒí’ˆ ë§¤ë ¥ ì™„ë²½ ì „ë‹¬"
            ]
            templates.extend(tape_templates)
        
        return templates
    
    async def _generate_fallback_response(self, request_time: str, recommendation_count: int) -> BroadcastResponse:
        """API í• ë‹¹ëŸ‰ ì†Œì§„ ì‹œ ì„ì‹œ ë°ì´í„°ë¡œ ì¶”ì²œ ê·¼ê±° ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        
        # ì„ì‹œ ìƒí’ˆ ë°ì´í„° (ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ìƒí’ˆë“¤)
        mock_products = [
            {
                "product_code": "P001",
                "product_name": "í”„ë¦¬ë¯¸ì—„ ë‹¤ì´ì–´íŠ¸ ë³´ì¡°ì œ",
                "category_main": "ê±´ê°•ì‹í’ˆ",
                "tape_code": "T001",
                "tape_name": "í”„ë¦¬ë¯¸ì—„ ë‹¤ì´ì–´íŠ¸ ë³´ì¡°ì œ"
            },
            {
                "product_code": "P002", 
                "product_name": "í™ˆíŠ¸ë ˆì´ë‹ ì„¸íŠ¸",
                "category_main": "ìŠ¤í¬ì¸ ìš©í’ˆ",
                "tape_code": "T002",
                "tape_name": "í™ˆíŠ¸ë ˆì´ë‹ ì„¸íŠ¸ ì™„ì „ì •ë³µ"
            },
            {
                "product_code": "P005",
                "product_name": "ì‹œì›í•œ ì—¬ë¦„ ì„ í’ê¸°",
                "category_main": "ê°€ì „ì œí’ˆ",
                "tape_code": "T005",
                "tape_name": "ì‹œì›í•œ ì—¬ë¦„ë‚˜ê¸° ì„ í’ê¸°"
            }
        ]
        
        # ì„ì‹œ í›„ë³´ ë°ì´í„° ìƒì„±
        mock_candidates = []
        for i, product in enumerate(mock_products[:recommendation_count]):
            candidate = {
                "product": product,
                "source": "trend" if i == 0 else "category",
                "base_score": 0.8 - i * 0.1,
                "trend_boost": 1.3 if i == 0 else 1.0,
                "predicted_sales": 85000000 - i * 15000000,
                "final_score": 0.85 - i * 0.1,
                "trend_keyword": "ë‹¤ì´ì–´íŠ¸" if i == 0 else ""
            }
            mock_candidates.append(candidate)
        
        # ì„ì‹œ ì¹´í…Œê³ ë¦¬ ë°ì´í„°
        mock_categories = [
            RecommendedCategory(rank=1, name="ê±´ê°•ì‹í’ˆ", reason="íŠ¸ë Œë“œ ê¸‰ìƒìŠ¹", predictedSales="ë†’ìŒ"),
            RecommendedCategory(rank=2, name="ìŠ¤í¬ì¸ ìš©í’ˆ", reason="ì‹œì¦Œ ì í•©ì„±", predictedSales="ì•ˆì •ì "),
            RecommendedCategory(rank=3, name="ê°€ì „ì œí’ˆ", reason="ë‚ ì”¨ ì—°ê´€ì„±", predictedSales="ë³´í†µ")
        ]
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = {
            "time_slot": "ì €ë…",
            "weather": {"weather": "í­ì—¼"},
            "competitors": []
        }
        
        # ê°œì„ ëœ ì¶”ì²œ ê·¼ê±° ì‹œìŠ¤í…œìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        response = await self._format_response(mock_candidates, mock_categories, context)
        response.requestTime = request_time
        
        logger.info(f"í´ë°± ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(mock_candidates)}ê°œ ì¶”ì²œ (ì¶”ì²œ ê·¼ê±° ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸)")
        return response
    
    async def _generate_dynamic_reason_with_langchain(self, candidate: Dict[str, Any], context: Dict[str, Any] = None) -> str:
        """LangChainì„ í™œìš©í•œ ë™ì  ì¶”ì²œ ê·¼ê±° ìƒì„±"""
        try:
            product = candidate["product"]
            source = candidate["source"]
            trend_boost = candidate.get("trend_boost", 1.0)
            predicted_sales = candidate.get("predicted_sales", 0)
            
            # ìƒí’ˆ ì •ë³´
            category = product.get("category_main", "")
            product_name = product.get("product_name", "")
            trend_keyword = candidate.get("trend_keyword", "")
            tape_name = product.get("tape_name", "")
            
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            time_slot = context.get("time_slot", "") if context else ""
            weather = context.get("weather", {}).get("weather", "") if context else ""
            competitors = context.get("competitors", []) if context else []
            
            # ê²½ìŸ ìƒí™© ë¶„ì„
            competitor_categories = [comp.get("category_main", "") for comp in competitors]
            has_competition = category in competitor_categories
            
            # í”„ë¡¬í”„íŠ¸ ë¡œê¹… (ëˆˆì— ë„ê²Œ)
            print("=" * 80)
            print("[LLM í”„ë¡¬í”„íŠ¸] ì¶”ì²œ ê·¼ê±° ìƒì„±")
            print("=" * 80)
            print(f"ìƒí’ˆ: {product_name}, ì¹´í…Œê³ ë¦¬: {category}, ë§¤ì¶œ: {predicted_sales}ë§Œì›")
            print(f"ì‹œê°„ëŒ€: {time_slot}, ë‚ ì”¨: {weather}")
            print("=" * 80)
            logger.info(f"[LLM í”„ë¡¬í”„íŠ¸] ì¶”ì²œ ê·¼ê±° ìƒì„± - ìƒí’ˆ: {product_name}, ì¹´í…Œê³ ë¦¬: {category}, ë§¤ì¶œ: {predicted_sales}ë§Œì›")
            
            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
            reason_prompt = ChatPromptTemplate.from_messages([
                ("system", """ë‹¹ì‹ ì€ í™ˆì‡¼í•‘ ë°©ì†¡ í¸ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ìƒí’ˆ ì •ë³´ì™€ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°„ê²°í•˜ê³  ì„¤ë“ë ¥ ìˆëŠ” ì¶”ì²œ ê·¼ê±°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ì£¼ì„¸ìš”:
1. **ì •í™•íˆ í•œ ë¬¸ì¥**ìœ¼ë¡œ ì‘ì„± (ìµœëŒ€ 100ì)
2. **ì˜ˆìƒ ë§¤ì¶œ ìˆ˜ì¹˜ëŠ” ë°˜ë“œì‹œ í¬í•¨** (ì˜ˆ: "2500ë§Œì›")
3. ì‹œì²­ìê°€ ì¦‰ì‹œ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‰¬ìš´ í‘œí˜„
4. ê¸ì •ì ì´ê³  í™•ì‹ ì— ì°¬ í†¤ì•¤ë§¤ë„ˆ ìœ ì§€

# ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì‘ì„± ê°€ì´ë“œ
**1ìˆœìœ„ - ê³µíœ´ì¼ (ìˆì„ ê²½ìš° í•„ìˆ˜ ì–¸ê¸‰)**
- ê³µíœ´ì¼ëª… + íŠ¹ìˆ˜/ì—°íœ´/ì‹œì¦Œ ë“±ì˜ í‘œí˜„ ì‚¬ìš©
- ì˜ˆ: "ì„¤ ì—°íœ´ íŠ¹ìˆ˜ë¡œ", "ì¶”ì„ ì‹œì¦Œ ë§ì•„", "í¬ë¦¬ìŠ¤ë§ˆìŠ¤ íŠ¹ìˆ˜ë¡œ"

**2ìˆœìœ„ - ì˜ˆìƒ ë§¤ì¶œ ìˆ˜ì¹˜ (í•­ìƒ í•„ìˆ˜)**
- ë°˜ë“œì‹œ "ë§Œì›" ë‹¨ìœ„ë¡œ ëª…ì‹œ
- ì˜ˆ: "2500ë§Œì› ë§¤ì¶œ ì˜ˆìƒ", "1800ë§Œì› ê¸°ëŒ€"

**3ìˆœìœ„ - ì‹œê°„ëŒ€/ë‚ ì”¨**
- ì‹œê°„ëŒ€: "ì €ë… ì‹œê°„ëŒ€ ìµœì ", "ì˜¤í›„ íƒ€ì„ ì¶”ì²œ"
- ë‚ ì”¨: "ë¹„ ì˜¤ëŠ” ë‚  ì¸ê¸°", "ë¬´ë”ìœ„ í•´ê²°ì‚¬"

**4ìˆœìœ„ - ì¹´í…Œê³ ë¦¬/íŠ¸ë Œë“œ**
- ì¹´í…Œê³ ë¦¬: "ê±´ê°•ì‹í’ˆ ì‹œì¦Œ", "í™”ì¥í’ˆ ì„±ìˆ˜ê¸°"
- íŠ¸ë Œë“œ: ì‹¤ì œ í‚¤ì›Œë“œê°€ ìˆì„ ë•Œë§Œ ì‚¬ìš©

# ì‘ì„± íŒ¨í„´ (ë°˜ë“œì‹œ ë”°ë¥¼ ê²ƒ)
## ê³µíœ´ì¼ O + ë§¤ì¶œ:
"{ê³µíœ´ì¼ëª…} íŠ¹ìˆ˜ë¡œ {ë§¤ì¶œ}ë§Œì› ë§¤ì¶œ ì˜ˆìƒ"
"{ê³µíœ´ì¼ëª…} ì—°íœ´ ë§ì•„ {ë§¤ì¶œ}ë§Œì› ê¸°ëŒ€"

## ê³µíœ´ì¼ X + ì‹œê°„ëŒ€ + ë§¤ì¶œ:
"{ì‹œê°„ëŒ€} ì‹œê°„ëŒ€ ìµœì , {ë§¤ì¶œ}ë§Œì› ì˜ˆìƒ"
"{ì‹œê°„ëŒ€} íƒ€ì„ ì¶”ì²œ, {ë§¤ì¶œ}ë§Œì› ê¸°ëŒ€"

## ê³µíœ´ì¼ X + ë‚ ì”¨ + ë§¤ì¶œ:
"{ë‚ ì”¨} ë‚  ì¸ê¸° ìƒí’ˆ, {ë§¤ì¶œ}ë§Œì› ì˜ˆì¸¡"
"{ë‚ ì”¨} ëŒ€ë¹„ í•„ìˆ˜í…œ, {ë§¤ì¶œ}ë§Œì› ì „ë§"

**ì ˆëŒ€ í•˜ì§€ ë§ ê²ƒ:**
- ë‘ ë¬¸ì¥ ì´ìƒ ì‘ì„± ê¸ˆì§€
- ì• ë§¤í•œ í‘œí˜„ ê¸ˆì§€ (ì˜ˆ: "ì¢‹ì€", "ì ì ˆí•œ")
- ë§¤ì¶œ ìˆ˜ì¹˜ ëˆ„ë½ ê¸ˆì§€
- ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ê³¼ë‹¤ ì‚¬ìš© ê¸ˆì§€"""),
    
    ("human", """
ìƒí’ˆëª…: {product_name}
ì¹´í…Œê³ ë¦¬: {category}
ì˜ˆì¸¡ ë§¤ì¶œ: {predicted_sales}ë§Œì›
ì‹œê°„ëŒ€: {time_slot}
ë‚ ì”¨: {weather}
ê³µíœ´ì¼: {holiday_name}
íŠ¸ë Œë“œ í‚¤ì›Œë“œ: {trend_keyword}

**ì§€ì‹œì‚¬í•­:**
1. ê³µíœ´ì¼ì´ "{holiday_name}"ë¡œ ì œê³µë˜ë©´ ë°˜ë“œì‹œ ì²« ë²ˆì§¸ë¡œ ì–¸ê¸‰í•˜ì„¸ìš”
2. ì˜ˆì¸¡ ë§¤ì¶œ "{predicted_sales}ë§Œì›"ì€ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”
3. ê³µíœ´ì¼ì´ ì—†ìœ¼ë©´ ì‹œê°„ëŒ€({time_slot})ì™€ ë‚ ì”¨({weather})ë¥¼ í™œìš©í•˜ì„¸ìš”
4. ìœ„ ì‘ì„± íŒ¨í„´ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì„œ ì •í™•íˆ ë”°ë¥´ì„¸ìš”

""")
            ])
            
            chain = reason_prompt | self.llm
            
            # ê³µíœ´ì¼ ì •ë³´ ì¶”ê°€
            holiday_name = context.get("holiday_name") if context else None
            
            result = await chain.ainvoke({
                "product_name": product_name,
                "category": category,
                "source": "íŠ¸ë Œë“œ" if source == "trend" else "ì¹´í…Œê³ ë¦¬",
                "trend_keyword": trend_keyword or "ì—†ìŒ",
                "predicted_sales": int(predicted_sales / 10000),  # ë§Œì› ë‹¨ìœ„
                "time_slot": time_slot or "ë¯¸ì§€ì •",
                "weather": weather or "ë³´í†µ",
                "holiday_name": holiday_name if holiday_name else "ì—†ìŒ"
            })
            
            return result.content.strip()
            
        except Exception as e:
            logger.error(f"ë™ì  ê·¼ê±° ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()  # ì—ëŸ¬ ìƒì„¸ ë¡œê·¸
            # í´ë°±: ê°„ë‹¨í•œ ê¸°ë³¸ ë©”ì‹œì§€ (í…œí”Œë¦¿ ì•„ë‹Œ)
            return f"{candidate['product'].get('category_main', 'ìƒí’ˆ')} ì¶”ì²œ"
    
    async def _predict_category_sales(self, category: str, broadcast_dt: datetime) -> float:
        """ì¹´í…Œê³ ë¦¬ë³„ XGBoost ë§¤ì¶œ ì˜ˆì¸¡"""
        try:
            # XGBoost ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì¤€ë¹„
            import pandas as pd
            
            dummy_data = pd.DataFrame([{
                # Numeric features
                "product_price": 100000,
                "product_avg_profit": 30000000,
                "product_broadcast_count": 10,
                "category_timeslot_avg_profit": 25000000,
                "hour": broadcast_dt.hour,
                "temperature": 20,
                "precipitation": 0,
                
                # Categorical features
                "product_lgroup": category,
                "product_mgroup": category,
                "product_sgroup": category,
                "brand": "Unknown",
                "product_type": "ìœ í˜•",
                "time_slot": self._get_time_slot(broadcast_dt),
                "day_of_week": ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"][broadcast_dt.weekday()],
                "season": self._get_season(broadcast_dt.month),
                "weather": "Clear",
                
                # Boolean features
                "is_weekend": 1 if broadcast_dt.weekday() >= 5 else 0,
                "is_holiday": 0
            }])
            
            logger.info(f"=== ì¹´í…Œê³ ë¦¬ ë§¤ì¶œ ì˜ˆì¸¡ ì…ë ¥ ===")
            logger.info(f"ì¹´í…Œê³ ë¦¬: {category}, ì‹œê°„: {broadcast_dt.hour}ì‹œ")
            
            # XGBoost íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì˜ˆì¸¡ (ì „ì²˜ë¦¬ í¬í•¨)
            predicted_sales = self.model.predict(dummy_data)[0]
            logger.info(f"=== ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡ ê²°ê³¼ ===")
            logger.info(f"{category}: {predicted_sales:,.0f}ì› ({predicted_sales/100000000:.2f}ì–µ)")
            
            return float(predicted_sales)
            
        except Exception as e:
            logger.error(f"ì¹´í…Œê³ ë¦¬ ë§¤ì¶œ ì˜ˆì¸¡ ì˜¤ë¥˜ ({category}): {e}")
            import traceback
            logger.error(f"ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")
            return 50000000  # ê¸°ë³¸ê°’ (0.5ì–µ)
    
    def _prepare_features_for_product(self, product: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """1ê°œ ìƒí’ˆì˜ XGBoost feature ì¤€ë¹„ (ì˜ˆì¸¡ì€ ì•ˆ í•¨)"""
        broadcast_dt = context["broadcast_dt"]
        
        print(f"=== [_prepare_features_for_product] í˜¸ì¶œë¨: {product.get('product_name', 'Unknown')[:30]} ===")
        
        # ìƒí’ˆë³„ ê³¼ê±° í‰ê·  ë§¤ì¶œ ì¡°íšŒ (DBì—ì„œ)
        product_code = product.get("product_code", product.get("productId"))
        category_main = product.get("category_main", product.get("category", "Unknown"))
        print(f"  product_code: {product_code}, category: {category_main}")
        product_avg_profit = self._get_product_avg_profit(product_code, category_main)
        
        # ì¹´í…Œê³ ë¦¬-ì‹œê°„ëŒ€ë³„ í‰ê·  ë§¤ì¶œ ì¡°íšŒ
        category_main = product.get("category_main", product.get("category", "Unknown"))
        time_slot = context["time_slot"]
        category_timeslot_avg = self._get_category_timeslot_avg(category_main, time_slot)
        
        return {
            # Numeric features
            "product_price": product.get("product_price", product.get("price", 100000)),
            "product_avg_profit": product_avg_profit,
            "product_broadcast_count": product.get("broadcast_count", 1),
            "category_timeslot_avg_profit": category_timeslot_avg,
            "hour": broadcast_dt.hour,
            "temperature": context["weather"].get("temperature", 20),
            "precipitation": context["weather"].get("precipitation", 0),
            
            # Categorical features
            "product_lgroup": category_main,
            "product_mgroup": product.get("category_middle", "Unknown"),
            "product_sgroup": product.get("category_sub", "Unknown"),
            "brand": product.get("brand", "Unknown"),
            "product_type": product.get("product_type", "ìœ í˜•"),
            "time_slot": time_slot,
            "day_of_week": ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"][broadcast_dt.weekday()],
            "season": context["season"],
            "weather": context["weather"].get("weather", "Clear"),
            
            # Boolean features
            "is_weekend": 1 if broadcast_dt.weekday() >= 5 else 0,
            "is_holiday": 0
        }
    
    def _get_product_avg_profit(self, product_code: str, category: str = None) -> float:
        """ìƒí’ˆë³„ ê³¼ê±° í‰ê·  ë§¤ì¶œ ì¡°íšŒ (ì—†ìœ¼ë©´ ì¹´í…Œê³ ë¦¬ í‰ê·  ì‚¬ìš©)"""
        try:
            # 1. ìƒí’ˆë³„ í‰ê·  ì¡°íšŒ
            query = text(f"""
            SELECT COALESCE(AVG(gross_profit), 0) as avg_profit, COUNT(*) as cnt
            FROM broadcast_training_dataset
            WHERE product_code = '{product_code}'
            """)
            with self.engine.connect() as conn:
                result = conn.execute(query).fetchone()
            avg_profit = float(result[0]) if result and result[0] else 0
            count = int(result[1]) if result else 0
            
            if count > 0:
                print(f"âœ… ìƒí’ˆ '{product_code}': í‰ê·  {avg_profit/10000:.0f}ë§Œì› ({count}ê±´)")
                return avg_profit
            
            # 2. ê³¼ê±° ë°ì´í„° ì—†ìœ¼ë©´ ì¹´í…Œê³ ë¦¬ í‰ê·  ì‚¬ìš©
            if category:
                query = text(f"""
                SELECT COALESCE(AVG(gross_profit), 0) as avg_profit, COUNT(*) as cnt
                FROM broadcast_training_dataset
                WHERE category_main = '{category}'
                """)
                with self.engine.connect() as conn:
                    result = conn.execute(query).fetchone()
                category_avg = float(result[0]) if result and result[0] else 100000000  # ê¸°ë³¸ 1ì–µ
                cat_count = int(result[1]) if result else 0
                print(f"ğŸ“Š ìƒí’ˆ '{product_code}': ê³¼ê±° ë°ì´í„° ì—†ìŒ â†’ ì¹´í…Œê³ ë¦¬ '{category}' í‰ê·  {category_avg/10000:.0f}ë§Œì› ì‚¬ìš© ({cat_count}ê±´)")
                return category_avg
            
            # 3. ì¹´í…Œê³ ë¦¬ë„ ì—†ìœ¼ë©´ ì „ì²´ í‰ê· 
            query = text("SELECT AVG(gross_profit) FROM broadcast_training_dataset")
            with self.engine.connect() as conn:
                result = conn.execute(query).fetchone()
            overall_avg = float(result[0]) if result and result[0] else 100000000
            print(f"ğŸ“Š ìƒí’ˆ '{product_code}': ì „ì²´ í‰ê·  {overall_avg/10000:.0f}ë§Œì› ì‚¬ìš©")
            return overall_avg
            
        except Exception as e:
            logger.warning(f"ìƒí’ˆ í‰ê·  ë§¤ì¶œ ì¡°íšŒ ì‹¤íŒ¨ ({product_code}): {e}")
            return 100000000  # ê¸°ë³¸ 1ì–µ
    
    def _get_category_timeslot_avg(self, category: str, time_slot: str) -> float:
        """ì¹´í…Œê³ ë¦¬-ì‹œê°„ëŒ€ë³„ í‰ê·  ë§¤ì¶œ ì¡°íšŒ"""
        try:
            query = text(f"""
            SELECT COALESCE(AVG(gross_profit), 0) as avg_profit
            FROM broadcast_training_dataset
            WHERE category_main = '{category}'
              AND time_slot = '{time_slot}'
            """)
            with self.engine.connect() as conn:
                result = conn.execute(query).fetchone()
            return float(result[0]) if result and result[0] else 0
        except Exception as e:
            logger.warning(f"ì¹´í…Œê³ ë¦¬-ì‹œê°„ëŒ€ í‰ê·  ì¡°íšŒ ì‹¤íŒ¨ ({category}, {time_slot}): {e}")
            return 0
    
    async def _predict_product_sales(self, product: Dict[str, Any], context: Dict[str, Any]) -> float:
        """ê°œë³„ ìƒí’ˆ XGBoost ë§¤ì¶œ ì˜ˆì¸¡"""
        try:
            import pandas as pd
            
            # Feature ì¤€ë¹„
            features = self._prepare_features_for_product(product, context)
            product_data = pd.DataFrame([features])
            
            logger.info(f"=== XGBoost ë§¤ì¶œ ì˜ˆì¸¡ ì…ë ¥ ë°ì´í„° ===")
            logger.info(f"ìƒí’ˆ: {product.get('product_name', 'Unknown')}")
            logger.info(f"ì¹´í…Œê³ ë¦¬: {product.get('category_main', 'Unknown')}")
            logger.info(f"ê°€ê²©: {product.get('product_price', 100000):,}ì›")
            logger.info(f"ê³¼ê±° í‰ê·  ë§¤ì¶œ: {product.get('avg_sales', 30000000):,}ì›")
            logger.info(f"ë°©ì†¡ ì‹œê°„: {context['broadcast_dt'].hour}ì‹œ")
            logger.info(f"ë‚ ì”¨: {context['weather'].get('weather', 'Clear')}, {context['weather'].get('temperature', 20)}Â°C")
            
            # XGBoost íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì˜ˆì¸¡ (ì „ì²˜ë¦¬ í¬í•¨)
            predicted_sales = self.model.predict(product_data)[0]
            logger.info(f"=== XGBoost ì˜ˆì¸¡ ê²°ê³¼ ===")
            logger.info(f"ì˜ˆì¸¡ ë§¤ì¶œ: {predicted_sales:,.0f}ì› ({predicted_sales/100000000:.2f}ì–µ)")
            
            return float(predicted_sales)
            
        except Exception as e:
            logger.error(f"ìƒí’ˆ ë§¤ì¶œ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            logger.error(f"ìƒí’ˆ ì •ë³´: {product.get('product_name', 'Unknown')}")
            import traceback
            logger.error(f"ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")
            return 30000000  # ê¸°ë³¸ê°’ (0.3ì–µ)
    
    async def _predict_products_sales_batch(self, products: List[Dict[str, Any]], context: Dict[str, Any]) -> List[float]:
        """ì—¬ëŸ¬ ìƒí’ˆ XGBoost ë§¤ì¶œ ì˜ˆì¸¡ (ë°°ì¹˜ ì²˜ë¦¬)"""
        try:
            import pandas as pd
            
            if not products:
                return []
            
            # ëª¨ë“  ìƒí’ˆì˜ featuresë¥¼ í•œ ë²ˆì— ì¤€ë¹„
            features_list = [
                self._prepare_features_for_product(product, context)
                for product in products
            ]
            
            batch_df = pd.DataFrame(features_list)
            
            print(f"=== [ë°°ì¹˜ ì˜ˆì¸¡] {len(products)}ê°œ ìƒí’ˆ ì¼ê´„ ì˜ˆì¸¡ ì‹œì‘ ===")
            
            # ì…ë ¥ í”¼ì²˜ ìƒ˜í”Œ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            print(f"=== [ì…ë ¥ í”¼ì²˜ ìƒ˜í”Œ] ===")
            for i, (product, features) in enumerate(zip(products[:3], features_list[:3])):
                print(f"  ìƒí’ˆ {i+1}: {product.get('product_name', '')[:30]}")
                print(f"    - product_avg_profit: {features['product_avg_profit']:,.0f}ì›")
                print(f"    - category_timeslot_avg: {features['category_timeslot_avg_profit']:,.0f}ì›")
                print(f"    - product_price: {features['product_price']:,.0f}ì›")
                print(f"    - ì¹´í…Œê³ ë¦¬: {features['product_lgroup']}")
            
            # XGBoost ë°°ì¹˜ ì˜ˆì¸¡ (í•œ ë²ˆì— ì²˜ë¦¬)
            predicted_sales_array = self.model.predict(batch_df)
            
            print(f"=== [ë°°ì¹˜ ì˜ˆì¸¡] ì™„ë£Œ ===")
            print(f"  í‰ê· : {predicted_sales_array.mean()/10000:.0f}ë§Œì›")
            print(f"  ìµœì†Œ: {predicted_sales_array.min()/10000:.0f}ë§Œì›")
            print(f"  ìµœëŒ€: {predicted_sales_array.max()/10000:.0f}ë§Œì›")
            print(f"  í‘œì¤€í¸ì°¨: {predicted_sales_array.std()/10000:.0f}ë§Œì›")
            
            # ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ ì¶œë ¥
            print(f"=== [ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ] ===")
            for i, (product, sales) in enumerate(zip(products[:5], predicted_sales_array[:5])):
                print(f"  {i+1}. {product.get('product_name', '')[:30]:30s} â†’ {sales/10000:.0f}ë§Œì›")
            
            return [float(sales) for sales in predicted_sales_array]
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ë§¤ì¶œ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(f"ìƒì„¸ ì—ëŸ¬:\n{traceback.format_exc()}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return [30000000.0] * len(products)
    
    async def _get_all_categories_from_db(self) -> List[str]:
        """PostgreSQLì—ì„œ ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì¡°íšŒ"""
        try:
            query = text("""
                SELECT DISTINCT category_main
                FROM broadcast_training_dataset
                WHERE category_main IS NOT NULL
                ORDER BY category_main
            """)
            
            with self.engine.connect() as conn:
                result = conn.execute(query).fetchall()
            
            categories = [row[0] for row in result]
            return categories
            
        except Exception as e:
            logger.error(f"ì „ì²´ ì¹´í…Œê³ ë¦¬ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    async def _get_ace_products_from_category(self, category: str, limit: int = 5) -> List[Dict[str, Any]]:
        """ì¹´í…Œê³ ë¦¬ë³„ ì—ì´ìŠ¤ ìƒí’ˆ ì¡°íšŒ"""
        try:
            query = text("""
                SELECT product_code, product_name, category_main, category_middle, category_sub,
                       AVG(gross_profit) as avg_sales, COUNT(*) as broadcast_count,
                       tape_code, tape_name, MAX(price) as price
                FROM broadcast_training_dataset 
                WHERE category_main = :category
                GROUP BY product_code, product_name, category_main, category_middle, category_sub,
                         tape_code, tape_name
                ORDER BY avg_sales DESC 
                LIMIT :limit
            """)
            
            with self.engine.connect() as conn:
                result = conn.execute(query, {"category": category, "limit": limit}).fetchall()
                
            products = []
            for row in result:
                products.append({
                    "product_code": row[0],
                    "product_name": row[1],
                    "category_main": row[2],
                    "category_middle": row[3],
                    "category_sub": row[4],
                    "avg_sales": float(row[5]),
                    "broadcast_count": int(row[6]),
                    "tape_code": row[7],
                    "tape_name": row[8],
                    "price": float(row[9]) if row[9] else None
                })
            
            return products
            
        except Exception as e:
            logger.error(f"ì—ì´ìŠ¤ ìƒí’ˆ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []
    
    def _remove_duplicates(self, candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì œê±° - ê°™ì€ ìƒí’ˆì½”ë“œ ë° ê°™ì€ ì†Œë¶„ë¥˜(category_sub) ì œê±°"""
        seen_products = set()
        seen_sub_categories = set()
        unique_candidates = []
        
        for candidate in candidates:
            product_code = candidate.get("product_code", "")
            category_sub = candidate.get("category_sub", "")
            
            # ìƒí’ˆì½”ë“œ ì¤‘ë³µ ì²´í¬
            if product_code and product_code in seen_products:
                continue
            
            # ì†Œë¶„ë¥˜ ì¤‘ë³µ ì²´í¬ (ëŒ€/ì¤‘ë¶„ë¥˜ëŠ” ê°™ì•„ë„ OK, ì†Œë¶„ë¥˜ë§Œ ë‹¤ë¥´ë©´ OK)
            if category_sub and category_sub in seen_sub_categories:
                logger.info(f"ì†Œë¶„ë¥˜ ì¤‘ë³µ ì œì™¸: {candidate.get('product_name', '')} (ì†Œë¶„ë¥˜: {category_sub})")
                continue
            
            # í†µê³¼í•œ ê²½ìš° ì¶”ê°€
            if product_code:
                seen_products.add(product_code)
            if category_sub:
                seen_sub_categories.add(category_sub)
            unique_candidates.append(candidate)
        
        logger.info(f"ì¤‘ë³µ ì œê±° ì™„ë£Œ: {len(candidates)}ê°œ â†’ {len(unique_candidates)}ê°œ (ì†Œë¶„ë¥˜ ë‹¤ì–‘ì„± ë³´ì¥)")
        return unique_candidates
    
    def _rank_candidates(self, candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """í›„ë³´ ë­í‚¹"""
        return sorted(candidates, key=lambda x: x.get("final_score", 0), reverse=True)
    
    def _get_time_slot(self, dt: datetime) -> str:
        """ì‹œê°„ëŒ€ ë¶„ë¥˜"""
        hour = dt.hour
        if 6 <= hour < 9:
            return "ì•„ì¹¨"
        elif 9 <= hour < 12:
            return "ì˜¤ì „"
        elif 12 <= hour < 14:
            return "ì ì‹¬"
        elif 14 <= hour < 18:
            return "ì˜¤í›„"
        elif 18 <= hour < 22:
            return "ì €ë…"
        else:
            return "ì•¼ê°„"
    
    def _get_season(self, month: int) -> str:
        """ê³„ì ˆ ë¶„ë¥˜"""
        if 3 <= month <= 5:
            return "ë´„"
        elif 6 <= month <= 8:
            return "ì—¬ë¦„"
        elif 9 <= month <= 11:
            return "ê°€ì„"
        else:
            return "ê²¨ìš¸"
